{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "We have two populations Blue (privileged) and Red (unprivileged), with the Blue population being 9 times larger than the Red population.\n",
    "\n",
    "Individuals from both populations are requesting to attend XAI training to improve competency in this important area. Number of places is limited. The administrators of the training have decided to give priority to enrolling individuals who may need this training in the future, although unfortunately it is difficult to predict who will benefit.\n",
    "\n",
    "The decision rule adopted:\n",
    "1. In the Red group, half of the people will find the skills useful in future and half will not. Administrators randomly allocate 50% of people to training.\n",
    "2. in the Blue group, 80% of people will find the training useful in future and 20% will not, although of course it is not known who will find it useful. The administrators have built a predictive model based on user behaviour in predicting for whom it will be useful and whom will not. The model has the following performance:\n",
    "\n",
    "\n",
    "| Blue                     \t| Will use XAI \t| Will not use XAI \t| Total \t|\n",
    "|--------------------------\t|--------------\t|------------------\t|-------\t|\n",
    "| Enrolled in training     \t| 60           \t| 5               \t| 65    \t|\n",
    "| not enrolled in training \t| 20            \t| 15               \t| 35    \t|\n",
    "| Total                    \t| 80           \t| 20               \t| 100   \t|\n",
    "\n",
    "\n",
    "Task: Calculate the Demographic parity, equal opportunity and predictive rate parity coefficients for this decision rule.\n",
    "\n",
    "Starred task: How can this decision rule be changed to improve its fairness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "Let $G$ - be a random variable that denotes the protected attribute (in this case group; $G=0$ for red and $G=1$ for blue).  \n",
    "Let $Y$ - be a random variable that denotes whether a person will use XAI in the future ($Y=1$ denotes that a person will use XAI in the future and $Y=0$ that a person won't use XAI in the future ).  \n",
    "Let $E$ - be a random variable that denotes whether a person was enrolled in the course ($E=1$ mean enrolled and $E = 0$ means not enrolled).  \n",
    "\n",
    "### Demographic parity can be defined as follows:  \n",
    "$P(E=1 | G=0) = P(E=1 | G=1)$  \n",
    "and the coefficient  \n",
    "$\\frac{P(E=1 | G=0)}{P(E=1 | G=1)} = \\frac{0.5}{0.65} = 0.769230769231$  \n",
    "One can note that here the assigment is a bit unfair, as according to lecture range $[0.8;1.2]$ is preferred.  \n",
    "\n",
    "\n",
    "### Equal opportunity can be defined as follows:  \n",
    "$P(E=1 | Y = 1, G = 0) = P(E=1 | Y = 1, G = 1)$   \n",
    "with the coefficient  \n",
    "$\\frac{P(E=1 | Y = 1, G = 0)}{P(E=1 | Y = 1, G = 1)} = \\frac{0.5}{0.75} = \\frac{2}{3} - 0.667$  \n",
    "\n",
    "\n",
    "### For predictive rate parity we calculate  positive predictive parity and negative predictive parity can be defined as follows\n",
    "\n",
    "Positive predictive parity can be defined as follows:  \n",
    "$P(Y=1 | E = 1, G = 0) = P(Y=1 | E = 1, G = 1)$   \n",
    "with the coefficient  \n",
    "$\\frac{P(Y=1 | E = 1, G = 0) }{P(Y=1 | E = 1, G = 1)} = \\frac{0.5}{\\frac{60}{65}} = \\frac{65}{120} = \\frac{13}{24} = 0.541$  \n",
    "\n",
    "\n",
    "Negative predictive parity can be defined as follows:  \n",
    "$P(Y=1 | E = 0, G = 0) = P(Y=1 | E = 0, G = 1)$   \n",
    "with the coefficient  \n",
    "$\\frac{P(Y=1 | E = 0, G = 0) }{P(Y=1 | E = 0, G = 1)} = \\frac{0.5}{\\frac{20}{35}} = \\frac{35}{40} = \\frac{7}{8} = 0.875$ \n",
    "\n",
    "\n",
    "### How to improve the coefficients?\n",
    "One simple solution is to increase the probability of enrolling people from the red group.  \n",
    "For example when choosing the probability to be $\\frac{20}{35}$ we get\n",
    "$\\frac{P(E=1 | G=0)}{P(E=1 | G=1)} = 0.879120879120879$  \n",
    "$\\frac{P(E=1 | Y = 1, G = 0)}{P(E=1 | Y = 1, G = 1)} = 0.7619047619047619$  \n",
    "$\\frac{P(Y=1 | E = 1, G = 0) }{P(Y=1 | E = 1, G = 1)} = 0.619047619047619$  \n",
    "$\\frac{P(Y=1 | E = 0, G = 0) }{P(Y=1 | E = 0, G = 1)} = 1.0$ \n",
    "\n",
    "If we aim only at improving  Demographic parity then we can set the probability for the red group to $0.65$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2\n",
    "\n",
    "For this homework, train few models on a selected dataset from https://github.com/ahxt/fair_fairness_benchmark/:\n",
    "\n",
    "Prepare a knitr/jupiter notebook with the following points.\n",
    "Submit your results on GitHub to the directory `Homeworks/HW1`.\n",
    "\n",
    "1. Train a model for the selected dataset. \n",
    "2. For the selected protected attribute (age, gender, race) calculate the following fairness coefficients: Statistical parity, Equal opportunity, Predictive parity.\n",
    "3. Train another model (different hyperparameters, feature transformations etc., different family of models) and see how the coefficients Statistical parity, Equal opportunity, Predictive parity behave for it. Are they different/similar?\n",
    "4. Apply the selected bias mitigation technique (like data balancing) on the first model. Check how Statistical parity, Equal opportunity, Predictive parity coefficients behave after this mittigation.\n",
    "5. Compare the quality (performance) of the three models with their fairness coefficients. Is there any correlation/trade off? \n",
    "6. ! COMMENT on the results obtained in (2)-(5)\n",
    "\n",
    "\n",
    "## Alternative task\n",
    "\n",
    "Alternative homework\n",
    "\n",
    "If you prefer proving theorems instead of calculations,\n",
    "then instead of the above assignments, \n",
    "you can prove that except for trivial situations \n",
    "(independence between a decision with a group), \n",
    "no two of the three fairness equalities \n",
    "(demographic parity, equal opportunity, predictive rate parity) \n",
    "can occur simultaneously.\n",
    "\n",
    "\n",
    "## **Important note:**\n",
    "\n",
    "Try to convert the jupyter notebook into an HTML file, e.g. using the following command in bash\n",
    "\n",
    "```\n",
    "jupyter nbconvert --to=html --template=classic FILE_NAME.ipynb\n",
    "```\n",
    "\n",
    "The submitted homework should consist of two parts:\n",
    "\n",
    "1. The 1st part is the key results and comments from points (2)-(5). In this part **PLEASE DO NOT SHOW ANY R/PYTHON CODES, ONLY RESULTS (FIGURES, COMMENTS).**\n",
    "2. The 2nd part should start with the word \"Appendix\" or \"Załącznik\" and should include the reproducible R/Python code used to implement points (1)-(5).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point 1\n",
    "We train a single Linear Layer.   \n",
    "With regularization, the model achieves good results on train and test sets within a few epochs.  \n",
    "This is one of the simplest models, as it can only linearly weight features to form a prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point 2\n",
    "\n",
    "We select the gender attribute. We ensure the model does not have access to this attribute during the training and evaluation.  \n",
    "We train 10 models and measure Statistical parity, Equal opportunity, and Predictive parity on the test set. The results are attached below.  \n",
    "We observe that the models are remarkably unfair when considering equal opportunity.  \n",
    "We can observe that the models failed to identify women with high salaries in the test set.\n",
    "Further investigation into the data unravels that the train and test data are around 33% females.  \n",
    "What is more in the train data only 15% of high-salary people are females.\n",
    "This can be the reason for the lack of Equal opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Train Accuracy\": {\n",
      "    \"value\": \"76.7% +- 0.3\"\n",
      "  },\n",
      "  \"Test Accuracy\": {\n",
      "    \"value\": \"76.7% +- 0.2\"\n",
      "  },\n",
      "  \"Statistical parity\": {\n",
      "    \"value\": \"30.0% +- 12.5\"\n",
      "  },\n",
      "  \"Equal opportunity\": {\n",
      "    \"value\": \"0.0% +- 0.0\"\n",
      "  },\n",
      "  \"Positive predictive parity\": {\n",
      "    \"value\": \"90.0% +- 30.0\"\n",
      "  },\n",
      "  \"Negative predictive parity\": {\n",
      "    \"value\": \"36.2% +- 0.1\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def plot_data(data):\n",
    "\n",
    "    names = []\n",
    "    values = []\n",
    "    stds = []\n",
    "\n",
    "    brief_results = {}\n",
    "\n",
    "    for k, v in data.items():\n",
    "        names.append(k)\n",
    "        values.append(np.mean(v))\n",
    "        stds.append(np.std(v))\n",
    "        brief_results[k] = {\n",
    "            \"value\": f\"{values[-1]*100:.1f}% +- {stds[-1]*100:.1f}\"\n",
    "        }\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.bar(names, values)\n",
    "    plt.errorbar(\n",
    "        names,\n",
    "        values,\n",
    "        stds,\n",
    "        fmt=\".\",\n",
    "        color=\"Black\",\n",
    "        elinewidth=2,\n",
    "        capthick=10,\n",
    "        errorevery=1,\n",
    "        alpha=0.5,\n",
    "        ms=4,\n",
    "        capsize=2,\n",
    "    )\n",
    "    plt.ylim(0, 2)\n",
    "    plt.show()\n",
    "    print(json.dumps(brief_results, indent=2))\n",
    "\n",
    "\n",
    "exp1_data = {'Train Accuracy': [0.7660084366798401, 0.7725499868392944, 0.7654862999916077, 0.7631215453147888, 0.7657627463340759, 0.7690488696098328, 0.7693559527397156, 0.7695402503013611, 0.7616166472434998, 0.7670833468437195], 'Test Accuracy': [0.7715128064155579, 0.7643879652023315, 0.7662919759750366, 0.766906201839447, 0.7697315812110901, 0.7664762735366821, 0.7660462856292725, 0.7652478218078613, 0.7657392024993896, 0.7667833566665649], 'Statistical parity': [0.3557297885417938, 0.0, 0.41244831681251526, 0.3727107644081116, 0.31003767251968384, 0.379006564617157, 0.3877394497394562, 0.18212004005908966, 0.2072400450706482, 0.39089176058769226], 'Equal opportunity': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Positive predictive parity': [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'Negative predictive parity': [0.36094293261038035, 0.363792594030022, 0.36182020302885015, 0.361977067761774, 0.362462880973088, 0.3620570216011652, 0.36213712085178934, 0.36363637044606123, 0.3636375185000986, 0.3618187522840974]}\n",
    "\n",
    "\n",
    "plot_data(exp1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 3\n",
    "We train 10 simple Swiglu-inspired models, that should have greater capabilities.  \n",
    "We observe that they have lower variance, better train and test set accuracy, and on average better statistical parity coefficient.\n",
    "This is not suprising as those models are more expressive. However they still fail at equal opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Train Accuracy\": {\n",
      "    \"value\": \"83.5% +- 0.0\"\n",
      "  },\n",
      "  \"Test Accuracy\": {\n",
      "    \"value\": \"77.8% +- 0.5\"\n",
      "  },\n",
      "  \"Statistical parity\": {\n",
      "    \"value\": \"46.5% +- 4.5\"\n",
      "  },\n",
      "  \"Equal opportunity\": {\n",
      "    \"value\": \"0.0% +- 0.0\"\n",
      "  },\n",
      "  \"Positive predictive parity\": {\n",
      "    \"value\": \"89.7% +- 5.4\"\n",
      "  },\n",
      "  \"Negative predictive parity\": {\n",
      "    \"value\": \"35.5% +- 0.4\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "exp2_data = {'Train Accuracy': [0.8355701565742493, 0.8348944783210754, 0.8353244662284851, 0.8352937698364258, 0.8350480794906616, 0.8352630734443665, 0.8348023891448975, 0.8349559307098389, 0.8351094722747803, 0.835201621055603], 'Test Accuracy': [0.7787604928016663, 0.7807260155677795, 0.7730483412742615, 0.773908257484436, 0.772986888885498, 0.7769793272018433, 0.7785148620605469, 0.7860696315765381, 0.7866838574409485, 0.773908257484436], 'Statistical parity': [0.48467427492141724, 0.5061770677566528, 0.40977007150650024, 0.42454472184181213, 0.41289809346199036, 0.48005837202072144, 0.4560404419898987, 0.53014075756073, 0.5269279479980469, 0.41401955485343933], 'Equal opportunity': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Positive predictive parity': [0.8701754351842217, 0.859045759047395, 0.9853574512091914, 0.9049657560108297, 0.9855324267881331, 0.9017201066090681, 0.8746838994979308, 0.8242809320028235, 0.8296935048568537, 0.9343715229552395], 'Negative predictive parity': [0.3543193296076082, 0.35220900206066963, 0.358722841495906, 0.3591010453033186, 0.3586415825127496, 0.3547010881548059, 0.35584695909770386, 0.3478771255876427, 0.34739712500282677, 0.3589525200363936]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_data(exp2_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 4\n",
    "We prepare a new training dataset by choosing equal number of positive and negative samples for each gender.   \n",
    "That is in our dataset the number of high earning females is equal to the number of high earning males, and the same hold for people with lower salaries.  \n",
    "We observe a decrease in accurancy, high variance in statistical parity and the highest average equal opportunity.  \n",
    "However, as noted, the predictive power of the models reduced due to change of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABRQAAAKZCAYAAADJb6dgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbn0lEQVR4nO3de5xVZb0/8O8ww1y4zKggtxgFb3hD8FKEeU0MzOOR08VLlkheysQ0UouOgrdzUEu8FMrJRNREzVSsVNQoNBVFUTJ/4iAIAcmAYjCCOcDM8/vDFzs3DLAGgeHyfr9e+wV7rWc9+7v2rGfNms9ee62ClFIKAAAAAIAMmjV1AQAAAADA1kOgCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABk1qhAcfjw4fHZz342WrduHe3atYv+/ftHVVXVepd74IEHYu+9947S0tLo3r17PPbYY3nzU0oxdOjQ6NixY5SVlUWfPn3irbfeatyaAAAAAACbXKMCxaeffjrOO++8eOGFF+Kpp56KFStWxJe+9KVYtmzZWpd5/vnn49RTT40zzzwzXn311ejfv3/0798/Xn/99Vyb6667Lm6++eYYNWpUvPjii9GyZcvo27dvfPTRRxu+ZgAAAADARleQUkobuvC7774b7dq1i6effjqOOOKIBtucfPLJsWzZsvjDH/6Qm/b5z38+evbsGaNGjYqUUnTq1Cl++MMfxkUXXRQREUuWLIn27dvHmDFj4pRTTtnQ8gAAAACAjazo0yy8ZMmSiIjYaaed1tpm0qRJMXjw4Lxpffv2jXHjxkVExKxZs6K6ujr69OmTm19RURG9evWKSZMmNRgo1tbWRm1tbe55fX19vP/++9GmTZsoKCj4NKsEAAAAANudlFJ88MEH0alTp2jWbN1fat7gQLG+vj4uvPDC+MIXvhD777//WttVV1dH+/bt86a1b98+qqurc/NXTVtbm9UNHz48rrjiig0tHQAAAABowNy5c6Nz587rbLPBgeJ5550Xr7/+ejz77LMb2sUGGzJkSN5Zj0uWLIlddtkl5s6dG+Xl5Zu9HgAAAADYmtXU1ERlZWW0bt16vW03KFAcNGhQ/OEPf4hnnnlmvYllhw4dYsGCBXnTFixYEB06dMjNXzWtY8eOeW169uzZYJ8lJSVRUlKyxvTy8nKBIgAAAABsoCyXE2zUXZ5TSjFo0KB4+OGH409/+lN07dp1vcv07t07JkyYkDftqaeeit69e0dERNeuXaNDhw55bWpqauLFF1/MtQEAAAAAtgyNOkPxvPPOi7Fjx8YjjzwSrVu3zl3jsKKiIsrKyiIi4vTTT4/PfOYzMXz48IiIuOCCC+LII4+M66+/Po4//vi477774uWXX45f/vKXEfFx6nnhhRfG1VdfHXvuuWd07do1LrvssujUqVP0799/I64qAAAAAPBpNSpQvPXWWyMi4qijjsqbfscdd8QZZ5wRERFz5szJuxPMoYceGmPHjo1LL700fvKTn8See+4Z48aNy7uRyyWXXBLLli2Lc845JxYvXhyHHXZYjB8/PkpLSzdwtQAAAACATaEgpZSauohPq6amJioqKmLJkiWuoQgAAAAAjdSYfK1R11AEAAAAALZvAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAILNGB4rPPPNMnHDCCdGpU6coKCiIcePGrbP9GWecEQUFBWs89ttvv1ybyy+/fI35e++9d6NXBgAAAADYtBodKC5btix69OgRI0eOzNT+pptuivnz5+cec+fOjZ122im+/vWv57Xbb7/98to9++yzjS0NAAAAANjEihq7wHHHHRfHHXdc5vYVFRVRUVGRez5u3Lj45z//GQMHDswvpKgoOnTo0NhyAAAAAIDNaLNfQ/H222+PPn36xK677po3/a233opOnTrFbrvtFqeddlrMmTNnrX3U1tZGTU1N3gMAAAAA2PQ2a6D4zjvvxOOPPx5nnXVW3vRevXrFmDFjYvz48XHrrbfGrFmz4vDDD48PPvigwX6GDx+eO/OxoqIiKisrN0f5AAAAALDdK0gppQ1euKAgHn744ejfv3+m9sOHD4/rr78+3nnnnSguLl5ru8WLF8euu+4aI0aMiDPPPHON+bW1tVFbW5t7XlNTE5WVlbFkyZIoLy9v9HoAAAAAwPaspqYmKioqMuVrjb6G4oZKKcXo0aPjW9/61jrDxIiIHXbYIfbaa6+YMWNGg/NLSkqipKRkU5QJAAAAAKzDZvvK89NPPx0zZsxo8IzD1S1dujRmzpwZHTt23AyVAQAAAABZNTpQXLp0aUydOjWmTp0aERGzZs2KqVOn5m6iMmTIkDj99NPXWO7222+PXr16xf7777/GvIsuuiiefvrpmD17djz//PPxX//1X1FYWBinnnpqY8sDAAAAADahRn/l+eWXX46jjz4693zw4MERETFgwIAYM2ZMzJ8/f407NC9ZsiQefPDBuOmmmxrsc968eXHqqafGokWLYuedd47DDjssXnjhhdh5550bWx4AAAAAsAl9qpuybCkac9FIAAAAACBfY/K1zXYNRQAAAABg6ydQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAya3Sg+Mwzz8QJJ5wQnTp1ioKCghg3btw620+cODEKCgrWeFRXV+e1GzlyZHTp0iVKS0ujV69eMXny5MaWBgAAAABsYo0OFJctWxY9evSIkSNHNmq5qqqqmD9/fu7Rrl273Lz7778/Bg8eHMOGDYtXXnklevToEX379o2FCxc2tjwAAAAAYBMqauwCxx13XBx33HGNfqF27drFDjvs0OC8ESNGxNlnnx0DBw6MiIhRo0bFo48+GqNHj44f//jHjX4tAAAAAGDT2GzXUOzZs2d07Ngxjj322Hjuuedy05cvXx5TpkyJPn36/LuoZs2iT58+MWnSpAb7qq2tjZqamrwHAAAAALDpbfJAsWPHjjFq1Kh48MEH48EHH4zKyso46qij4pVXXomIiPfeey/q6uqiffv2ecu1b99+jessrjJ8+PCoqKjIPSorKzf1agAAAAAAsQFfeW6sbt26Rbdu3XLPDz300Jg5c2bccMMNcffdd29Qn0OGDInBgwfnntfU1AgVAQAAAGAz2OSBYkM+97nPxbPPPhsREW3bto3CwsJYsGBBXpsFCxZEhw4dGly+pKQkSkpKNnmdAAAAAEC+zXYNxU+aOnVqdOzYMSIiiouL4+CDD44JEybk5tfX18eECROid+/eTVEeAAAAALAWjT5DcenSpTFjxozc81mzZsXUqVNjp512il122SWGDBkS//jHP+Kuu+6KiIgbb7wxunbtGvvtt1989NFH8atf/Sr+9Kc/xZNPPpnrY/DgwTFgwIA45JBD4nOf+1zceOONsWzZstxdnwEAAACALUOjA8WXX345jj766NzzVdcyHDBgQIwZMybmz58fc+bMyc1fvnx5/PCHP4x//OMf0aJFizjggAPij3/8Y14fJ598crz77rsxdOjQqK6ujp49e8b48ePXuFELAAAAANC0ClJKqamL+LRqamqioqIilixZEuXl5U1dDgAAAABsVRqTrzXJNRQBAAAAgK2TQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyKzRgeIzzzwTJ5xwQnTq1CkKCgpi3Lhx62z/0EMPxbHHHhs777xzlJeXR+/eveOJJ57Ia3P55ZdHQUFB3mPvvfdubGkAAAAAwCbW6EBx2bJl0aNHjxg5cmSm9s8880wce+yx8dhjj8WUKVPi6KOPjhNOOCFeffXVvHb77bdfzJ8/P/d49tlnG1saAAAAALCJFTV2geOOOy6OO+64zO1vvPHGvOf/+7//G4888kj8/ve/jwMPPPDfhRQVRYcOHRpbDgAAAACwGW32ayjW19fHBx98EDvttFPe9Lfeeis6deoUu+22W5x22mkxZ86ctfZRW1sbNTU1eQ8AAAAAYNPb7IHiz372s1i6dGmcdNJJuWm9evWKMWPGxPjx4+PWW2+NWbNmxeGHHx4ffPBBg30MHz48Kioqco/KysrNVT4AAAAAbNcKUkppgxcuKIiHH344+vfvn6n92LFj4+yzz45HHnkk+vTps9Z2ixcvjl133TVGjBgRZ5555hrza2tro7a2Nve8pqYmKisrY8mSJVFeXt7o9QAAAACA7VlNTU1UVFRkytcafQ3FDXXffffFWWedFQ888MA6w8SIiB122CH22muvmDFjRoPzS0pKoqSkZFOUCQAAAACsw2b5yvO9994bAwcOjHvvvTeOP/749bZfunRpzJw5Mzp27LgZqgMAAAAAsmr0GYpLly7NO3Nw1qxZMXXq1Nhpp51il112iSFDhsQ//vGPuOuuuyLi4685DxgwIG666abo1atXVFdXR0REWVlZVFRURETERRddFCeccELsuuuu8c4778SwYcOisLAwTj311I2xjgAAAADARtLoMxRffvnlOPDAA+PAAw+MiIjBgwfHgQceGEOHDo2IiPnz5+fdofmXv/xlrFy5Ms4777zo2LFj7nHBBRfk2sybNy9OPfXU6NatW5x00knRpk2beOGFF2LnnXf+tOsHAAAAAGxEn+qmLFuKxlw0EgAAAADI15h8bbNcQxEAAAAA2DYIFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzBodKD7zzDNxwgknRKdOnaKgoCDGjRu33mUmTpwYBx10UJSUlMQee+wRY8aMWaPNyJEjo0uXLlFaWhq9evWKyZMnN7Y0AAAAAGATa3SguGzZsujRo0eMHDkyU/tZs2bF8ccfH0cffXRMnTo1LrzwwjjrrLPiiSeeyLW5//77Y/DgwTFs2LB45ZVXokePHtG3b99YuHBhY8sDAAAAADahgpRS2uCFCwri4Ycfjv79+6+1zY9+9KN49NFH4/XXX89NO+WUU2Lx4sUxfvz4iIjo1atXfPazn41f/OIXERFRX18flZWVcf7558ePf/zj9dZRU1MTFRUVsWTJkigvL9/Q1QEAAACA7VJj8rVNfg3FSZMmRZ8+ffKm9e3bNyZNmhQREcuXL48pU6bktWnWrFn06dMn12Z1tbW1UVNTk/cAAAAAADa9TR4oVldXR/v27fOmtW/fPmpqauJf//pXvPfee1FXV9dgm+rq6gb7HD58eFRUVOQelZWVm6x+AAAAAODftsq7PA8ZMiSWLFmSe8ydO7epSwIAAACA7ULRpn6BDh06xIIFC/KmLViwIMrLy6OsrCwKCwujsLCwwTYdOnRosM+SkpIoKSnZZDUDAAAAAA3b5Gco9u7dOyZMmJA37amnnorevXtHRERxcXEcfPDBeW3q6+tjwoQJuTYAAAAAwJah0YHi0qVLY+rUqTF16tSIiJg1a1ZMnTo15syZExEffx359NNPz7X/7ne/G2+//XZccskl8eabb8Ytt9wSv/nNb+IHP/hBrs3gwYPjtttuizvvvDOmTZsW5557bixbtiwGDhz4KVcPAAAAANiYGv2V55dffjmOPvro3PPBgwdHRMSAAQNizJgxMX/+/Fy4GBHRtWvXePTRR+MHP/hB3HTTTdG5c+f41a9+FX379s21Ofnkk+Pdd9+NoUOHRnV1dfTs2TPGjx+/xo1aAAAAAICmVZBSSk1dxKdVU1MTFRUVsWTJkigvL2/qcgAAAABgq9KYfG2rvMszAAAAANA0BIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJBZUVMXAACwqQwfPrzB6UOGDNnMlQAAwLZDoAgAbLNqa2ubugQAANjm+MozAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmbnLMwCwzZs7d27U1dVFYWFhVFZWNnU5AACwVRMoAgDbvHnz5kVtbW2UlJQIFNkuDR8+vMHpQ4YM2cyVAADbAoEiAABs42pra5u6BABgG+IaigAAAABAZgJFAAAAACAzgSIAAAAAkJlrKAIA26ySkpKIiCgqKoqVK1dGUVFRbhoAALBhBIoAwDZr1R1sR4wYETU1NVFeXh6DBw9u4qoAAGDrJlAEAIDtxNy5c6Ouri4KCwujsrKyqcsBALZSAkUAANhOzJs3L2pra6OkpESgCABsMDdlAQAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmbsoCAADbuJKSkoiIKCoqipUrV0ZRUVFuGgBAYwkUAQBgGzdkyJCIiBgxYkTU1NREeXl5DB48uImrAgC2Vr7yDAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkVtTUBQCwaQwfPrzB6UOGDNnMlQAAALAtESgCbKNqa2ubugQAAAC2Qb7yDAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGbu8gywjZs7d27U1dVFYWFhVFZWNnU5AAAAbOUEigDbuHnz5kVtbW2UlJQIFAEAAPjUfOUZAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJm5KQvANqqkpCQiIoqKimLlypVRVFSUmwYAAAAbSqAIsI0aMmRIRESMGDEiampqory8PAYPHtzEVQEAALC185VnAAAAACAzgSIAAAAAkJlAEQAAAADIzDUU2SYNHz68wemrrikHAAAAwIYRKLJNqq2tbeoSAAAAALZJvvIMAAAAAGQmUAQAAAAAMtugQHHkyJHRpUuXKC0tjV69esXkyZPX2vaoo46KgoKCNR7HH398rs0ZZ5yxxvx+/fptSGkAAAAAwCbU6Gso3n///TF48OAYNWpU9OrVK2688cbo27dvVFVVRbt27dZo/9BDD8Xy5ctzzxctWhQ9evSIr3/963nt+vXrF3fccUfueUlJSWNLAwAAAAA2sUafoThixIg4++yzY+DAgbHvvvvGqFGjokWLFjF69OgG2++0007RoUOH3OOpp56KFi1arBEolpSU5LXbcccdN2yNAAAAAIBNplGB4vLly2PKlCnRp0+ff3fQrFn06dMnJk2alKmP22+/PU455ZRo2bJl3vSJEydGu3btolu3bnHuuefGokWL1tpHbW1t1NTU5D2gIXPnzo3Zs2fH3Llzm7oUAAAAgG1CowLF9957L+rq6qJ9+/Z509u3bx/V1dXrXX7y5Mnx+uuvx1lnnZU3vV+/fnHXXXfFhAkT4tprr42nn346jjvuuKirq2uwn+HDh0dFRUXuUVlZ2ZjVYDsyb968mD17dsybN6+pSwEAAADYJjT6Goqfxu233x7du3ePz33uc3nTTznllNz/u3fvHgcccEDsvvvuMXHixDjmmGPW6GfIkCExePDg3POamhqhIgAAAABsBo06Q7Ft27ZRWFgYCxYsyJu+YMGC6NChwzqXXbZsWdx3331x5plnrvd1dtttt2jbtm3MmDGjwfklJSVRXl6e9wAAAAAANr1GBYrFxcVx8MEHx4QJE3LT6uvrY8KECdG7d+91LvvAAw9EbW1tfPOb31zv68ybNy8WLVoUHTt2bEx5AAAAAMAm1ui7PA8ePDhuu+22uPPOO2PatGlx7rnnxrJly2LgwIEREXH66afHkCFD1lju9ttvj/79+0ebNm3ypi9dujQuvvjieOGFF2L27NkxYcKEOPHEE2OPPfaIvn37buBqAQAAAACbQqOvoXjyySfHu+++G0OHDo3q6uro2bNnjB8/Pnejljlz5kSzZvk5ZVVVVTz77LPx5JNPrtFfYWFhvPbaa3HnnXfG4sWLo1OnTvGlL30prrrqqigpKdnA1WJ7t2rbKSoqipUrV0ZRUZHtCQAAtmPDhw9vcHpDJ8QAsG4bdFOWQYMGxaBBgxqcN3HixDWmdevWLVJKDbYvKyuLJ554YkPKgLVadVAwYsSIqKmpifLy8rwb+QAAANuX2trapi4BYJvR6K88AwAAAADbL4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADLboLs8AwAAwNZo7ty5UVdXF4WFhVFZWdnU5QBslQSKAAAAbDfmzZsXtbW1UVJSIlAE2EC+8gwAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzNyUBQAAgG1eSUlJREQUFRXFypUro6ioKDcNgMYRKAIAALDNGzJkSEREjBgxImpqaqK8vDwGDx7cxFUBbJ185RkAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGZFTV0AbEoLFy6MefPmRefOnZu6FAAAAIBtgkCRbVZVVVVMnDgxFi9eHDNmzIiqqqro1q1bU5cFAAAAsFUTKG5Fuvz40aYuYavyr7enxPsz50ez0tZRv2h+HHHZ/VG228FNXdZWYfY1xzd1CQAAAMAWyjUU2WYVVbSPZs1Lo/7DxdGseWkUVbRv6pIAAAAAtnrOUGSb1bxN5yjdpXus/GBRFLVuE83buI4iAAAAwKclUGSbVthihygoKo5mxS2auhQAAACAbYKvPAMAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADIrauoCAAAAANj0hg8f3uD0IUOGbOZK2NoJFAEAAAC2A7W1tU1dAtsIX3kGAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM3d5BgAAANiOzJ07N+rq6qKwsDAqKyubuhy2QgJFAAAAgO3IvHnzora2NkpKSgSKbBCBItukJZN+ExERH817I1Ld8igoLI5UtyIqep/UxJUBAAAAbN0EimyTUt2Kj/9TXxdRXx9RUPfvaQAAAABsMDdlAQAAAAAyEygCAAAAAJn5yjMAAADAdqCkpCQiIoqKimLlypVRVFSUmwaNIVAEAAAA2A4MGTIkIiJGjBgRNTU1UV5eHoMHD27iqtga+cozAAAAAJCZMxTZphW2bhuR6iIKCpu6FAAAAIBtgkCRbVpRedumLgEAAABgm+IrzwAAAABAZs5QBNjGLVy4MObNmxedO3du6lIAAADYBggUAbZhVVVVMXHixFi8eHHMmDEjqqqqolu3bk1dFgAAAFsxgSKwVeny40ebuoStyr/enhLvz5wfzUpbR/2i+XHEZfdH2W4HN3VZW43Z1xzf1CUAAABscQSKbJMKCps3dQmwRSiqaB/NmpdG/YeLo1lJyyiqaN/UJQEAALCVEyiyTarofVJTlwBbhOZtOkfpLt1j5QeLoqh1m2jexnUUAQAA+HQEigDbuMIWO0RBUXE0K27R1KUAAACwDWjW1AUAAAAAAFsPgSIAAAAAkJlAEQAAAADITKAIAAAAAGQmUAQAAAAAMhMoAgAAAACZCRQBAAAAgMwEigAAAABAZhsUKI4cOTK6dOkSpaWl0atXr5g8efJa244ZMyYKCgryHqWlpXltUkoxdOjQ6NixY5SVlUWfPn3irbfe2pDSAAAAAIBNqNGB4v333x+DBw+OYcOGxSuvvBI9evSIvn37xsKFC9e6THl5ecyfPz/3+Pvf/543/7rrroubb745Ro0aFS+++GK0bNky+vbtGx999FHj1wgAAAAA2GQaHSiOGDEizj777Bg4cGDsu+++MWrUqGjRokWMHj16rcsUFBREhw4dco/27dvn5qWU4sYbb4xLL700TjzxxDjggAPirrvuinfeeSfGjRu3QSsFAAAAAGwajQoUly9fHlOmTIk+ffr8u4NmzaJPnz4xadKktS63dOnS2HXXXaOysjJOPPHE+H//7//l5s2aNSuqq6vz+qyoqIhevXqttc/a2tqoqanJewAAAAAAm16jAsX33nsv6urq8s4wjIho3759VFdXN7hMt27dYvTo0fHII4/Er3/966ivr49DDz005s2bFxGRW64xfQ4fPjwqKipyj8rKysasBgAAAACwgTb5XZ579+4dp59+evTs2TOOPPLIeOihh2LnnXeO//u//9vgPocMGRJLlizJPebOnbsRKwYAAAAA1qZRgWLbtm2jsLAwFixYkDd9wYIF0aFDh0x9NG/ePA488MCYMWNGRERuucb0WVJSEuXl5XkPAAAAAGDTa1SgWFxcHAcffHBMmDAhN62+vj4mTJgQvXv3ztRHXV1d/O1vf4uOHTtGRETXrl2jQ4cOeX3W1NTEiy++mLlPAAAAAGDzKGrsAoMHD44BAwbEIYccEp/73OfixhtvjGXLlsXAgQMjIuL000+Pz3zmMzF8+PCIiLjyyivj85//fOyxxx6xePHi+OlPfxp///vf46yzzoqIj+8AfeGFF8bVV18de+65Z3Tt2jUuu+yy6NSpU/Tv33/jrSkAAAAA8Kk1OlA8+eST4913342hQ4dGdXV19OzZM8aPH5+7qcqcOXOiWbN/n/j4z3/+M84+++yorq6OHXfcMQ4++OB4/vnnY9999821ueSSS2LZsmVxzjnnxOLFi+Owww6L8ePHR2lp6UZYRQAAAABgY2l0oBgRMWjQoBg0aFCD8yZOnJj3/IYbbogbbrhhnf0VFBTElVdeGVdeeeWGlAMAAAAAbCab/C7PAAAAAMC2Q6AIAAAAAGQmUAQAAAAAMhMoAgAAAACZCRQBAAAAgMw26C7PAABbk4ULF8a8efOic+fOTV0KAABs9QSKAMA2raqqKiZOnBiLFy+OGTNmRFVVVXTr1q2pywIAgK2WQBEAtkJdfvxoU5ew1fjX21Pi/Znzo1lp66hfND+OuOz+KNvt4KYua6sx+5rjm7oEAAC2MK6hCABs04oq2kez5qVR/+HiaNa8NIoq2jd1SQAAsFVzhiIAsE1r3qZzlO7SPVZ+sCiKWreJ5m1cRxEAAD4NgSIAsM0rbLFDFBQVR7PiFk1dCgAAbPV85RkAAAAAyEygCAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDMBIoAAAAAQGYCRQAAAAAgM4EiAAAAAJCZQBEAAAAAyEygCAAAAABkJlAEAAAAADIrauoCAACAzWPhwoUxb9686Ny5c1OXAgBsxQSKAACwHaiqqoqJEyfG4sWLY8aMGVFVVRXdunVr6rIAgK2QQBEAgK1Slx8/2tQlbFX+9faUeH/m/GhW2jrqF82PIy67P8p2O7ipy9oqzL7m+KYuAQC2KK6hCAAA24GiivbRrHlp1H+4OJo1L42iivZNXRIAsJVyhiIAAGwHmrfpHKW7dI+VHyyKotZtonkb11EEADaMQBEAALYThS12iIKi4mhW3KKpSwEAtmK+8gwAAAAAZCZQBAAAAAAyEygCAAAAAJkJFAEAAACAzASKAAAAAEBmAkUAAAAAIDOBIgAAAACQmUARAAAAAMhMoAgAAAAAZCZQBAAAAAAyEygCAAAAAJkVNXUBAAAAsLksXLgw5s2bF507d27qUgC2WgJFAAAAtgtVVVUxceLEWLx4ccyYMSOqqqqiW7duTV0WwFZHoAgAALCV6vLjR5u6hK3Kv96eEu/PnB/NSltH/aL5ccRl90fZbgc3dVlbjdnXHN/UJQBbCNdQBAAAYLtQVNE+mjUvjfoPF0ez5qVRVNG+qUsC2Co5QxEAAIDtQvM2naN0l+6x8oNFUdS6TTRv4zqKABtCoAgAAMB2o7DFDlFQVBzNils0dSkAWy1feQYAAAAAMhMoAgAAAACZ+cozAAAAwHZk4cKFMW/evOjc2XVE2TACRQAAAIDtRFVVVUycODEWL14cM2bMiKqqqujWrVtTl8VWRqAIAAAAbNW6/PjRpi5hq/Gvt6fE+zPnR7PS1lG/aH4ccdn9UbbbwU1d1lZj9jXHN3UJWwSBIsA2asmk30RExEfz3ohUtzwKCosj1a2Iit4nNXFlAABAUymqaB/NmpdG/YeLo1lJyyiqaN/UJbEVEigCbKNS3YqP/1NfF1FfH1FQ9+9pAADAdql5m85Rukv3WPnBoihq3Saat3EdRRpPoAgAAACwHSlssUMUFBVHs+IWTV0KW6lmTV0AAAAAALD1ECgCAAAAAJkJFAEAAACAzASKAAAAAEBmbsoCsI0rbN02ItVFFBQ2dSkAAABsAwSKANu4ovK2TV0CAAAA2xBfeQYAAAAAMhMoAgAAAACZCRQBAAAAgMwEigAAAABAZm7KArCNKihs3tQlAAAAsA0SKAJsoyp6n9TUJQAAALAN8pVnAAAAACCzDQoUR44cGV26dInS0tLo1atXTJ48ea1tb7vttjj88MNjxx13jB133DH69OmzRvszzjgjCgoK8h79+vXbkNIAAAAAgE2o0YHi/fffH4MHD45hw4bFK6+8Ej169Ii+ffvGwoULG2w/ceLEOPXUU+PPf/5zTJo0KSorK+NLX/pS/OMf/8hr169fv5g/f37uce+9927YGgEAAAAAm0yjA8URI0bE2WefHQMHDox99903Ro0aFS1atIjRo0c32P6ee+6J733ve9GzZ8/Ye++941e/+lXU19fHhAkT8tqVlJREhw4dco8dd9xxw9YIAAAAANhkGhUoLl++PKZMmRJ9+vT5dwfNmkWfPn1i0qRJmfr48MMPY8WKFbHTTjvlTZ84cWK0a9cuunXrFueee24sWrRorX3U1tZGTU1N3gMAAAAA2PQaFSi+9957UVdXF+3bt8+b3r59+6iurs7Ux49+9KPo1KlTXijZr1+/uOuuu2LChAlx7bXXxtNPPx3HHXdc1NXVNdjH8OHDo6KiIveorKxszGoAAAAAABuoaHO+2DXXXBP33XdfTJw4MUpLS3PTTznllNz/u3fvHgcccEDsvvvuMXHixDjmmGPW6GfIkCExePDg3POamhqhIgAAAABsBo06Q7Ft27ZRWFgYCxYsyJu+YMGC6NChwzqX/dnPfhbXXHNNPPnkk3HAAQess+1uu+0Wbdu2jRkzZjQ4v6SkJMrLy/MeAAAAAMCm16hAsbi4OA4++OC8G6qsusFK796917rcddddF1dddVWMHz8+DjnkkPW+zrx582LRokXRsWPHxpQHAAAAAGxijb7L8+DBg+O2226LO++8M6ZNmxbnnntuLFu2LAYOHBgREaeffnoMGTIk1/7aa6+Nyy67LEaPHh1dunSJ6urqqK6ujqVLl0ZExNKlS+Piiy+OF154IWbPnh0TJkyIE088MfbYY4/o27fvRlpNAAAAAGBjaPQ1FE8++eR49913Y+jQoVFdXR09e/aM8ePH527UMmfOnGjW7N855a233hrLly+Pr33ta3n9DBs2LC6//PIoLCyM1157Le68885YvHhxdOrUKb70pS/FVVddFSUlJZ9y9QAAAACAjWmDbsoyaNCgGDRoUIPzJk6cmPd89uzZ6+yrrKwsnnjiiQ0pAwAAAADYzBr9lWcAAAAAYPslUAQAAAAAMhMoAgAAAACZCRQBAAAAgMwEigAAAABAZgJFAAAAACAzgSIAAAAAkJlAEQAAAADITKAIAAAAAGQmUAQAAAAAMhMoAgAAAACZCRQBAAAAgMwEigAAAABAZgJFAAAAACAzgSIAAAAAkJlAEQAAAADITKAIAAAAAGQmUAQAAAAAMhMoAgAAAACZCRQBAAAAgMwEigAAAABAZgJFAAAAACAzgSIAAAAAkJlAEQAAAADITKAIAAAAAGQmUAQAAAAAMhMoAgAAAACZCRQBAAAAgMwEigAAAABAZgJFAAAAACAzgSIAAAAAkJlAEQAAAADITKAIAAAAAGQmUAQAAAAAMhMoAgAAAACZCRQBAAAAgMwEigAAAABAZgJFAAAAACAzgSIAAAAAkJlAEQAAAADITKAIAAAAAGQmUAQAAAAAMhMoAgAAAACZCRQBAAAAgMwEigAAAABAZgJFAAAAACAzgSIAAAAAkJlAEQAAAADITKAIAAAAAGQmUAQAAAAAMhMoAgAAAACZFTV1AQAAAABseksm/SYiIj6a90akuuVRUFgcqW5FVPQ+qYkrY2sjUAQAAADYDqS6FR//p74uor4+oqDu39OgEXzlGQAAAADITKAIAAAAAGQmUAQAAAAAMhMoAgAAAACZCRQBAAAAgMzc5RkAAABgO1LYum1EqosoKGzqUthKCRQBAAAAtiNF5W2bugS2cr7yDAAAAABkJlAEAAAAADITKAIAAAAAmQkUAQAAAIDM3JQFAAAAYDtQUNi8qUtgGyFQBAC2WUsm/SYiIj6a90akuuVRUFgcqW5FVPQ+qYkrAwDY/BwDsbFs0FeeR44cGV26dInS0tLo1atXTJ48eZ3tH3jggdh7772jtLQ0unfvHo899lje/JRSDB06NDp27BhlZWXRp0+feOuttzakNACAnFS3IlLdioj6uoj6+oj6uo+fAwAAG6zRgeL9998fgwcPjmHDhsUrr7wSPXr0iL59+8bChQsbbP/888/HqaeeGmeeeWa8+uqr0b9//+jfv3+8/vrruTbXXXdd3HzzzTFq1Kh48cUXo2XLltG3b9/46KOPNnzNAAAAAICNrtGB4ogRI+Lss8+OgQMHxr777hujRo2KFi1axOjRoxtsf9NNN0W/fv3i4osvjn322SeuuuqqOOigg+IXv/hFRHx8duKNN94Yl156aZx44olxwAEHxF133RXvvPNOjBs37lOtHAAAAACwcTXqGorLly+PKVOmxJAhQ3LTmjVrFn369IlJkyY1uMykSZNi8ODBedP69u2bCwtnzZoV1dXV0adPn9z8ioqK6NWrV0yaNClOOeWUNfqsra2N2tra3PMlS5ZERERNTU1jVmerU1/7YVOXwHZiSx5LxgGbk7Gw9UsrP/56c6qvi1RfF1HQLNLKFd6/RjAOti1p5fJIK1dEarbc+9cIxsG2xTjYcMYCbNnj4NNatW4ppfW2bVSg+N5770VdXV20b98+b3r79u3jzTffbHCZ6urqBttXV1fn5q+atrY2qxs+fHhcccUVa0yvrKzMtiLAOlXc2NQVwJbBWNg21c55LWpe/G1Tl7HVMA62XYv/cndTl7DVMA62XcZB4xgLsH2Mgw8++CAqKirW2WarvMvzkCFD8s56rK+vj/fffz/atGkTBQUFTVgZW5qampqorKyMuXPnRnl5eVOXA03COADjAFYxFsA4gAjjgIallOKDDz6ITp06rbdtowLFtm3bRmFhYSxYsCBv+oIFC6JDhw4NLtOhQ4d1tl/174IFC6Jjx455bXr27NlgnyUlJVFSUpI3bYcddmjMqrCdKS8vt5Nku2ccgHEAqxgLYBxAhHHAmtZ3ZuIqjbopS3FxcRx88MExYcKE3LT6+vqYMGFC9O7du8Flevfundc+IuKpp57Kte/atWt06NAhr01NTU28+OKLa+0TAAAAAGgajf7K8+DBg2PAgAFxyCGHxOc+97m48cYbY9myZTFw4MCIiDj99NPjM5/5TAwfPjwiIi644II48sgj4/rrr4/jjz8+7rvvvnj55Zfjl7/8ZUREFBQUxIUXXhhXX3117LnnntG1a9e47LLLolOnTtG/f/+Nt6YAAAAAwKfW6EDx5JNPjnfffTeGDh0a1dXV0bNnzxg/fnzupipz5syJZs3+feLjoYceGmPHjo1LL700fvKTn8See+4Z48aNi/333z/X5pJLLolly5bFOeecE4sXL47DDjssxo8fH6WlpRthFdmelZSUxLBhw9b4ijxsT4wDMA5gFWMBjAOIMA749ApSlntBAwAAAABEI6+hCAAAAABs3wSKAAAAAEBmAkUAAAAAIDOBIptVly5d4sYbb2zqMgDYAowZMyZ22GGHT9XHxv69ctRRR8WFF1640fprjIkTJ0ZBQUEsXry4SV6fptWU297WoKCgIMaNG9fUZWyTsu57tsXj+E9uV7Nnz46CgoKYOnXqBve3Mfpoatviz3lT2xbfM2NjTdviz/nTEijSoIKCgnU+Lr/88g3q96WXXopzzjlno9R47733RmFhYZx33nkbpT9Yl001Jlb13Zg/kr7zne9EYWFhPPDAAxv8mtCQd999N84999zYZZddoqSkJDp06BB9+/aN5557LtdmQ/+ob+gg7OSTT47p06dnWn5t4ePG/L3S1A499NCYP39+VFRURMTGCVxZtzPOOKPBfXq/fv2aurSt0qYM/ebPnx/HHXdcRGwbf5g21ie31eLi4thjjz3iyiuvjJUrV37qvrPue7al/W1DKisrY/78+bH//vtnan/GGWdE//79P1UfW6LVf85NGeav2u6vueaavOnjxo2LgoKCzV6PsWFsbCljY0tR1NQFsGWaP39+7v/3339/DB06NKqqqnLTWrVqlft/Sinq6uqiqGj9m9POO++80Wq8/fbb45JLLon/+7//i+uvvz5KS0s3Wt+NtXz58iguLm6y12fTa8yY2JQ+/PDDuO++++KSSy6J0aNHx9e//vXN8rprY9vftnz1q1+N5cuXx5133hm77bZbLFiwICZMmBCLFi3aJK9XVlYWZWVln6qPjfl7pSmtWLEiiouLo0OHDk1dynanX79+cccdd+RNKykpaaJqtk6b43eBsfHvbbW2tjYee+yxOO+886J58+YxZMiQT9Vv1n3Plrq/XbFiRTRv3vxT91NYWPipt7ON0UdTWTWOt7Sfc2lpaVx77bXxne98J3bcccemLqdBW9p7toqxsXFsqWNji5BgPe64445UUVGRe/7nP/85RUR67LHH0kEHHZSaN2+e/vznP6cZM2ak//zP/0zt2rVLLVu2TIccckh66qmn8vradddd0w033JB7HhHptttuS/37909lZWVpjz32SI888sh6a3r77bdTWVlZWrx4cerVq1e655571mhz++23p3333TcVFxenDh06pPPOOy8375///Gc655xzUrt27VJJSUnab7/90u9///uUUkrDhg1LPXr0yOvrhhtuSLvuumvu+YABA9KJJ56Yrr766tSxY8fUpUuXlFJKd911Vzr44INTq1atUvv27dOpp56aFixYkNfX66+/no4//vjUunXr1KpVq3TYYYelGTNmpKeffjoVFRWl+fPn57W/4IIL0mGHHbbe94TNZ/UxkVJKt912W9p7771TSUlJ6tatWxo5cmRuXm1tbTrvvPNShw4dUklJSdpll13S//7v/6aUPh4TEZF7fHI7a8iYMWPS5z//+bR48eLUokWLNGfOnLz5H330UbrkkktS586dU3Fxcdp9993Tr371q9z8tW1/KaV05JFHpgsuuCCvvxNPPDENGDAg93zXXXdNV155ZfrWt76VWrdunZt3ySWXpD333DOVlZWlrl27pksvvTQtX748r6/f/e536ZBDDkklJSWpTZs2qX///imllK644oq03377rbGuPXr0SJdeeuk63w82nn/+858pItLEiRPX2mZt2+v69v9HHnlk3nKrDj9WH0tTp05NRx11VGrVqlVq3bp1Ouigg9JLL72U+73zycewYcNyNX3y98q69u/vvfdeOuWUU1KnTp1SWVlZ2n///dPYsWPz1rGhcfBJq35HjBo1KnXu3DmVlZWlr3/962nx4sW5NpMnT059+vRJbdq0SeXl5emII45IU6ZMyesnItItt9ySTjjhhNSiRYs0bNiw3Hr+85//XOs6Gy8b16rf5+syffr0dPjhh6eSkpK0zz77pCeffDJFRHr44YdTSinv57bKq6++miIizZo1K6W0cba9lFK65ZZb0m677ZaaN2+e9tprr3TXXXflzV+1XfXr1y+Vlpamrl27pgceeCA3f9asWSki0r333pt69+6dGyOrj/uJEyemz372s7ljqB/96EdpxYoVebWed9556YILLkht2rRJRx111Fr3Dw29xxdccEE68sgj8/o7//zz08UXX5x23HHH1L59+9wY/+S6rXrPVx8bRx555DZ/HNXQ+3jsscemz3/+8ymllN5///30rW99K+2www6prKws9evXL02fPj3Xdvbs2ek//uM/0g477JBatGiR9t133/Too4+mlFKmfU9K+fvbU089NZ100kl59Sxfvjy1adMm3XnnnSmllOrq6tL//u//pi5duqTS0tJ0wAEH5G2PDVl1nHHKKaekFi1apE6dOqVf/OIXeW0a2n+mlNK4cePSgQcemEpKSlLXrl3T5Zdfnrfdrm8srxofr776am6ZtR03DRs2bI336c9//nNeH3V1dekzn/lMuuWWW/Lqf+WVV1JBQUGaPXt2Sunj31tnnnlmatu2bWrdunU6+uij09SpU9f6HmUZxytXrkzf/va3c+/9XnvtlW688ca8ftb298wnf84NjetZs2algoKC9NJLL+X1d8MNN6Rddtkl1dXVrbX2xhowYED6j//4j7T33nuniy++ODf94Ycfzh1LrPKXv/wlHXbYYam0tDR17tw5nX/++Wnp0qW5+e+880768pe/nEpLS1OXLl3SPffcs8YxxPXXX5/233//1KJFi9S5c+d07rnnpg8++CCllIwNY2OLGhtbCoEi67W2QPGAAw5ITz75ZJoxY0ZatGhRmjp1aho1alT629/+lqZPn54uvfTSVFpamv7+97/nlm0oUOzcuXMaO3Zseuutt9L3v//91KpVq7Ro0aJ11nTZZZelr33taymllH7+85+nL37xi3nzb7nlllRaWppuvPHGVFVVlSZPnpx73bq6uvT5z38+7bfffunJJ59MM2fOTL///e/TY489llLKHii2atUqfetb30qvv/56ev3111NKH4eYjz32WJo5c2aaNGlS6t27dzruuONyy82bNy/ttNNO6Stf+Up66aWXUlVVVRo9enR68803U0op7bXXXum6667LtV++fHlq27ZtGj169DrfDzav1cfEr3/969SxY8f04IMPprfffjs9+OCDaaeddkpjxoxJKaX005/+NFVWVqZnnnkmzZ49O/3lL3/J/SG5cOHCFBHpjjvuSPPnz08LFy5c52sffvjhuYOHr371q+nKK6/Mm3/SSSelysrK9NBDD6WZM2emP/7xj+m+++5LKa1/+8saKJaXl6ef/exnacaMGbkw8qqrrkrPPfdcmjVrVvrd736X2rdvn6699trccn/4wx9SYWFhGjp0aHrjjTfS1KlTc6Hq3LlzU7NmzdLkyZNz7VcdUMycOXOd7wcbz4oVK1KrVq3ShRdemD766KMG26xte13f/n/RokWpc+fO6corr0zz58/P/cG/+ljab7/90je/+c00bdq0NH369PSb3/wmTZ06NdXW1qYbb7wxlZeX55ZfdYD/yd8r69u/z5s3L/30pz9Nr776apo5c2a6+eabU2FhYXrxxRdzNWQJFFu2bJm++MUvpldffTU9/fTTaY899kjf+MY3cm0mTJiQ7r777jRt2rT0xhtvpDPPPDO1b98+1dTU5NpERGrXrl0aPXp0mjlzZvr73/+e90f92tbZeNm41hco1tXVpf333z8dc8wxaerUqenpp59OBx54YKMDxY2x7T300EOpefPmaeTIkamqqipdf/31qbCwMP3pT3/KtYmI1KZNm3TbbbelqqqqdOmll6bCwsL0xhtvpJT+/cdW586d029/+9v0xhtvpLPOOiu1bt06vffee7laW7Rokb73ve+ladOmpYcffji1bds2L+A78sgjU6tWrdLFF1+c3nzzzfTmm2+udf+QNVAsLy9Pl19+eZo+fXq68847U0FBQXryySfz1m3Vez558uQUEemPf/xjmj9/fu64cVs+jmroffzP//zPdNBBB+X+v88++6RnnnkmTZ06NfXt2zftscceuQ/3jj/++HTsscem1157LbdvfPrpp1NKKdO+J6X8/e0f/vCHVFZWlpuXUkq///3vU1lZWW5fd/XVV6e99947jR8/Ps2cOTPdcccdqaSkZL0fXLVu3ToNHz48VVVV5cbK6tvC6vvPZ555JpWXl6cxY8akmTNnpieffDJ16dIlXX755SmlbGN59dBkXcdNH3zwQTrppJNSv379cu9TbW3tGn1cdNFFawTaP/zhD/Om9enTJ51wwgnppZdeStOnT08//OEPU5s2bdb691CWcbx8+fI0dOjQ9NJLL6W33347/frXv04tWrRI999/f66ftf0988mf89rG9bHHHpu+973v5dV1wAEHpKFDh671Z7shVm33Dz30UCotLU1z585NKa0ZKM6YMSO1bNky3XDDDWn69OnpueeeSwceeGA644wzcm369OmTevbsmV544YU0ZcqUdOSRR6aysrK8v01vuOGG9Kc//SnNmjUrTZgwIXXr1i2de+65KaVkbBgbW9TY2FIIFFmvtQWK48aNW++y++23X/r5z3+ee95QoPjJMyqWLl2aIiI9/vjja+2zrq4uVVZW5l7/3XffTcXFxentt9/OtenUqVP67//+7waXf+KJJ1KzZs1SVVVVg/OzBort27dPtbW1a60zpZReeumlFBG5XyhDhgxJXbt2XePMrVWuvfbatM8+++SeP/jgg6lVq1Z5n67R9FYfE7vvvvsaZ5pcddVVqXfv3imllM4///z0xS9+MdXX1zfY3yd/Ya/L9OnTU/PmzdO7776bUvr4YKpr1665fquqqlJErHFm8Crr2/6yBoqrzixcl5/+9Kfp4IMPzj3v3bt3Ou2009ba/rjjjssdsKX08Xt21FFHrfd12Lh++9vfph133DGVlpamQw89NA0ZMiT99a9/zWuTdXtd3/4/pTXHUuvWrXNB/OoaOjN49X7Xt39vyPHHH59++MMf5p5nCRQLCwvTvHnzctMef/zx1KxZszXOjFqlrq4utW7dOnemZEofv48XXnhhXrvVg6m1rbPxsvEMGDAgFRYWppYtW+Y9/ud//iel9PE2VVRUlP7xj3/klnn88ccbHSg2pLHb3qGHHprOPvvsvGlf//rX05e//OXc84hI3/3ud/Pa9OrVK7e9rPpj65prrsnNX7FiRercuXPuQ6Cf/OQnqVu3bnm/s0aOHJlatWqVO7viyCOPTAceeOAaNTa0f8gaKK7+h+VnP/vZ9KMf/ajBvhs6Wyalbfs46pPvY319fXrqqadSSUlJuuiii9L06dNTRKTnnnsu1/69995LZWVl6Te/+U1KKaXu3bvnAoTVZd33fHJ/u2LFitS2bdu8s2RPPfXUdPLJJ6eUPv7GRIsWLdLzzz+f18eZZ56ZTj311LWu56677pr69euXN+3kk0/O+4C+of3nMccck/ugcpW77747dezYMaWUbSyvvl2t77ipoW179T5effXVVFBQkPuAbdWZWbfeemtK6eOz6srLy9f4IG/33XdP//d//9fg62YZxw0577zz0le/+tW8+hv6e6ahv9dWH9f3339/2nHHHXN1T5kyJRUUFKxzn7chPvkef/7zn0/f/va3U0prBopnnnlmOuecc/KW/ctf/pKaNWuW/vWvf6Vp06aliMg7c+ytt95KEbHGscknPfDAA6lNmza558bGqyklY2OVphwbWwo3ZWGDHXLIIXnPly5dGhdddFHss88+scMOO0SrVq1i2rRpMWfOnHX2c8ABB+T+37JlyygvL4+FCxeutf1TTz0Vy5Ytiy9/+csREdG2bds49thjY/To0RERsXDhwnjnnXfimGOOaXD5qVOnRufOnWOvvfbKtJ5r07179zWuFzRlypQ44YQTYpdddonWrVvHkUceGRGRew+mTp0ahx9++FqvZXHGGWfEjBkz4oUXXoiIjy/8e9JJJ0XLli0/Va1sOsuWLYuZM2fGmWeeGa1atco9rr766pg5c2ZEfPxznTp1anTr1i2+//3vx5NPPrlBrzV69Ojo27dvtG3bNiIivvzlL8eSJUviT3/6U0R8vH0VFhbmtrvVrW/7y2r1sR/x8XUlv/CFL0SHDh2iVatWcemll+aN/alTp651TEZEnH322XHvvffGRx99FMuXL4+xY8fGt7/97U9VJ4331a9+Nd5555343e9+F/369YuJEyfGQQcdFGPGjFnnchu6/1/d4MGD46yzzoo+ffrENddckxtDWa1v/15XVxdXXXVVdO/ePXbaaado1apVPPHEE42uc5dddonPfOYzuee9e/eO+vr63HVVFyxYEGeffXbsueeeUVFREeXl5bF06dI1XqehsZSF8bJxHX300TF16tS8x3e/+92IiJg2bVpUVlZGp06dcu179+7d6NfYGNvetGnT4gtf+ELetC984Qsxbdq0vGmr19e7d+91tikqKopDDjkk12batGnRu3fvvBsefOELX4ilS5fGvHnzctMOPvjgzLVn8cnjwYiIjh07rvN4sCHb+nHUH/7wh2jVqlWUlpbGcccdFyeffHJcfvnlMW3atCgqKopevXrl2rZp0ya6deuW+7l+//vfj6uvvjq+8IUvxLBhw+K11177VLUUFRXFSSedFPfcc09EfHw89Mgjj8Rpp50WEREzZsyIDz/8MI499ti846O77rprvfv2LNvw6vvPv/71r3HllVfmvdbZZ58d8+fPjw8//HCDxvLGOG7q2bNn7LPPPjF27NiIiHj66adj4cKFuWtg//Wvf42lS5dGmzZt8mqfNWtWo96n1cdxRMTIkSPj4IMPjp133jlatWoVv/zlL9fY5zT090wW/fv3j8LCwnj44Ycj4uOxdvTRR0eXLl0a3VdW1157bdx5551rbAsRH7+PY8aMyXsP+/btG/X19TFr1qyoqqqKoqKiOOigg3LL7LHHHmtck/GPf/xjHHPMMfGZz3wmWrduHd/61rdi0aJF8eGHH2au09jIxtjYNrgpCxts9YOziy66KJ566qn42c9+FnvssUeUlZXF1772tVi+fPk6+1l9R1RQUBD19fVrbX/77bfH+++/n3ch//r6+njttdfiiiuuWO8F/tc3v1mzZpFSypu2YsWKNdqtvv7Lli2Lvn37Rt++feOee+6JnXfeOebMmRN9+/bNvQfre+127drFCSecEHfccUd07do1Hn/88Zg4ceI6l6FpLV26NCIibrvttrwD+YiPLz4cEXHQQQfFrFmz4vHHH48//vGPcdJJJ0WfPn3it7/9bebXqaurizvvvDOqq6vzboBUV1cXo0ePjmOOOabJtv1JkybFaaedFldccUX07ds3Kioq4r777ovrr78+82ufcMIJUVJSEg8//HAUFxfHihUr4mtf+9o6l2HTKC0tjWOPPTaOPfbYuOyyy+Kss86KYcOGxRlnnLHWZTZ0/7+6yy+/PL7xjW/Eo48+Go8//ngMGzYs7rvvvviv//qvTMuvbzv76U9/GjfddFPceOON0b1792jZsmVceOGFja5zfQYMGBCLFi2Km266KXbdddcoKSmJ3r17r/E6GxpyGC8bV8uWLWOPPfbY4OWbNfv48/lP7j9X33durm1vc8q6/Wb93dLY48GGbOvHUUcffXTceuutUVxcHJ06dcp0Q8RVzjrrrOjbt288+uij8eSTT8bw4cPj+uuvj/PPP3+D6znttNPiyCOPjIULF8ZTTz0VZWVluTukrzo+evTRR/M+gInYODc9Wn37W7p0aVxxxRXxla98ZY22G3rjxk9707BVTjvttBg7dmz8+Mc/jrFjx0a/fv2iTZs2EfFx3R07dmxwO23obsJZ3XfffXHRRRfF9ddfH717947WrVvHT3/603jxxRfz2m3o76Hi4uI4/fTT44477oivfOUrMXbs2Ljppps2uN4sjjjiiOjbt28MGTJkjWOSpUuXxne+8534/ve/v8Zyu+yyS0yfPn29/c+ePTv+4z/+I84999z4n//5n9hpp53i2WefjTPPPDOWL18eLVq0yFyrsZGNsbH1Eyiy0Tz33HNxxhln5P7wW7p0acyePXujvsaiRYvikUceifvuuy/222+/3PS6uro47LDD4sknn4x+/fpFly5dYsKECXH00Uev0ccBBxwQ8+bNi+nTpzd4FsvOO+8c1dXVkVLKfTo/derU9db25ptvxqJFi+Kaa66JysrKiIh4+eWX13jtO++8c5133DrrrLPi1FNPjc6dO8fuu+++xtkIbFnat28fnTp1irfffjv3yWNDysvL4+STT46TTz45vva1r0W/fv3i/fffj5122imaN28edXV163ydxx57LD744IN49dVXc0FlRMTrr78eAwcOjMWLF0f37t2jvr4+nn766ejTp88afaxv+9t5553z7mZdV1cXr7/+eoPj6JOef/752HXXXeO///u/c9P+/ve/r/HaEyZMiIEDBzbYR1FRUQwYMCDuuOOOKC4ujlNOOWWjHazw6ey7774xbty43POGttcs+//i4uL1bucREXvttVfstdde8YMf/CBOPfXUuOOOO+K//uu/Mi2/vv37c889FyeeeGJ885vfjIiPP4yaPn167Lvvvuut65PmzJkT77zzTu7T/BdeeCGaNWsW3bp1y73OLbfckjuTfu7cufHee+816jUi1v6eGS+bzz777BNz586N+fPnR8eOHSMicme/rbLqro/z58/Pne2y+nHDxtj29tlnn3juuediwIABef2u3scLL7wQp59+et7zAw88cI02RxxxRERErFy5MqZMmRKDBg3Kvc6DDz6Ydxz03HPPRevWraNz587rrLGh/cPOO+8cr7/+et60qVOnfqozW1adNdLQ+NiWj6PWFn7vs88+sXLlynjxxRfj0EMPjYiPj5mrqqryto/Kysr47ne/G9/97ndjyJAhcdtttzUYKGbdXx966KFRWVkZ999/fzz++OPx9a9/Pfdz3XfffaOkpCTmzJmz1m9OrM3qY+yFF16IffbZZ53LHHTQQVFVVbXWDweyjOXVre+4Kev79I1vfCMuvfTSmDJlSvz2t7+NUaNG5dW96sPixp7BtK5x/Nxzz8Whhx4a3/ve93LtG3vW/yprO04966yzYv/9949bbrklVq5c2WBgtbFdc8010bNnz9zv21UOOuigeOONN9b68+/WrVusXLkyXn311dzZ1TNmzIh//vOfuTZTpkyJ+vr6uP7663MfFP3mN7/J68fY+Jix8bEtaWw0FV95ZqPZc88946GHHoqpU6fGX//61/jGN77R6E+W1+fuu++ONm3axEknnRT7779/7tGjR4/48pe/HLfffntEfHyWy/XXXx8333xzvPXWW/HKK6/Ez3/+84iIOPLII+OII46Ir371q/HUU0/lzhwbP358REQcddRR8e6778Z1110XM2fOjJEjR8bjjz++3tp22WWXKC4ujp///Ofx9ttvx+9+97u46qqr8toMGjQoampq4pRTTomXX3453nrrrbj77rtzX5OLiOjbt2+Ul5fH1VdfvdbwhS3LFVdcEcOHD4+bb745pk+fHn/729/ijjvuiBEjRkRExIgRI+Lee++NN998M6ZPnx4PPPBAdOjQIffp2qoAvLq6Ou/A5pNuv/32OP7446NHjx552/5JJ50UO+ywQ9xzzz3RpUuXGDBgQHz729+OcePGxaxZs2LixIm5g6H1bX9f/OIX49FHH41HH3003nzzzTj33HNj8eLF613/PffcM+bMmRP33XdfzJw5M26++ebcaf6rDBs2LO69994YNmxYTJs2Lf72t7/Ftddem9fmrLPOij/96U8xfvx4X99sAosWLYovfvGL8etf/zpee+21mDVrVjzwwANx3XXXxYknnphr19D2mmX/36VLl3jmmWfiH//4R4Ph2r/+9a8YNGhQTJw4Mf7+97/Hc889Fy+99FLuQLlLly6xdOnSmDBhQrz33nsNfv1offv3PffcM5566ql4/vnnY9q0afGd73wnFixY0Oj3qrS0NAYMGBB//etf4y9/+Ut8//vfj5NOOik6dOiQe5277747pk2bFi+++GKcdtppGxT4rWudjZeNp7a2Nqqrq/Meq7bRPn36xF577ZX38/7khycRH39trrKyMi6//PJ466234tFHH807Qzti42x7F198cYwZMyZuvfXWeOutt2LEiBHx0EMPxUUXXZTX7oEHHojRo0fH9OnTY9iwYTF58uTcH1KrjBw5Mh5++OF4880347zzzot//vOfue3oe9/7XsydOzfOP//8ePPNN+ORRx6JYcOGxeDBg3N/ZK9NQ/uHL37xi/Hyyy/HXXfdFW+99VYMGzZsjYCxsdq1axdlZWUxfvz4WLBgQSxZsiQ3b3s8jtpzzz3jxBNPjLPPPjueffbZ+Otf/xrf/OY34zOf+Uxu/33hhRfGE088EbNmzYpXXnkl/vznP681iMiyv13lG9/4RowaNSqeeuqpvA9WW7duHRdddFH84Ac/iDvvvDNmzpyZOx6/884717k+zz33XFx33XUxffr0GDlyZDzwwANxwQUXrHOZoUOHxl133RVXXHFF/L//9/9i2rRpcd9998Wll14aEdnG8urWd9zUpUuXeO2116Kqqiree++9Bs+8XdXu0EMPjTPPPDPq6uriP//zP3Pz+vTpE717947+/fvHk08+GbNnz47nn38+/vu//3uNExNWt65xvOeee8bLL78cTzzxREyfPj0uu+yyeOmll9bZ39qs7Th1n332ic9//vPxox/9KE499dTN8sFW9+7d47TTToubb745b/qPfvSjeP7552PQoEExderUeOutt+KRRx7J7fv23nvv6NOnT5xzzjkxefLkePXVV+Occ86JsrKy3Acne+yxR6xYsSL3t9zdd9+dF3BFGBurGBv/rn9LGRtNpikv4MjWYW03ZfnkxcdT+vgiqEcffXQqKytLlZWV6Re/+MUaFxjPciHTioqKdMcddzRYS/fu3de4a9Iq999/fyouLs7dsGLUqFGpW7duqXnz5qljx47p/PPPz7VdtGhRGjhwYGrTpk0qLS1N+++/f/rDH/6Qm3/rrbemysrK1LJly3T66aen//mf/1njpiwN3RVy7NixqUuXLqmkpCT17t07/e53v1vjouF//etf05e+9KXUokWL1Lp163T44YevcWfOyy67LBUWFqZ33nmnwXWlaTV0QeZ77rkn9ezZMxUXF6cdd9wxHXHEEemhhx5KKaX0y1/+MvXs2TO1bNkylZeXp2OOOSa98soruWV/97vfpT322CMVFRXlbWerVFdXp6KiotyF1Vd37rnn5i6O/69//Sv94Ac/SB07dkzFxcVpjz32yLu75bq2v+XLl6dzzz037bTTTqldu3Zp+PDhDd6UpaGLV1988cWpTZs2qVWrVunkk09ON9xwwxrv0YMPPph7j9q2bZu+8pWvrNHP4Ycfnvbbb78G15NN66OPPko//vGP00EHHZQqKipSixYtUrdu3dKll16aPvzww1y7hrbXLPv/SZMmpQMOOCCVlJTkLqT+ybFUW1ubTjnllFRZWZmKi4tTp06d0qBBg9K//vWvXB/f/e53U5s2bVJE5O44u/o2ua79+6JFi9KJJ56YWrVqldq1a5cuvfTSdPrpp+ftz7PclKVHjx7plltuSZ06dUqlpaXpa1/7Wnr//fdzbV555ZV0yCGHpNLS0rTnnnumBx54INPvv4Z+vza0zqsYL5/egAEDUkSs8ejWrVuuTVVVVTrssMNScXFx2muvvdL48ePX+Pk9++yzqXv37qm0tDQdfvjh6YEHHsi7KcvG2PZSSumWW25Ju+22W2revHnaa6+98i76n9LH29XIkSPTsccem0pKSlKXLl3y7ly56oL1Y8eOTZ/73OdScXFx2nffffPuFJ1SShMnTkyf/exnU3FxcerQoUP60Y9+lFasWLHeWtf2+2zo0KGpffv2qaKiIv3gBz9IgwYNWuOmLOu7Kdjq7/ltt92WKisrU7NmzfL6SmnbPI5a3x3J33///fStb30rVVRUpLKystS3b980ffr03PxBgwal3XffPZWUlKSdd945fetb38rd9TTrvqehY4A33ngjRUTadddd17j5XH19fbrxxhtzx+M777xz6tu3b+7u0g3Zdddd0xVXXJG+/vWvpxYtWqQOHTqkm266Ka9NQ/vPlFIaP358OvTQQ1NZWVkqLy9Pn/vc59Ivf/nL3Pz1jeWGbvazruOmhQsXpmOPPTa1atUqRUT685//vNYbBt1yyy0pItLpp5++Rt01NTXp/PPPT506dUrNmzdPlZWV6bTTTktz5sxp8D3KMo4/+uijdMYZZ6SKioq0ww47pHPPPTf9+Mc/zrvx5Nq2qdV/zus6Tr399ttTRKTJkyc3WOuntbabexQXF6fVo4zJkyfnfh4tW7ZMBxxwQO4GWyml9M4776TjjjsulZSUpF133TWNHTs2tWvXLo0aNSrXZsSIEaljx465MXTXXXcZG8nY+OTPYEsZG1uKgpRWu6gJ0OTOPPPMePfdd+N3v/tdU5cCm01KKfbcc8/43ve+F4MHD27qcqBBl19+eYwbNy7TpTA2JeOlaRUUFMTDDz8c/fv3b+pS8qyvrtmzZ0fXrl3j1VdfjZ49e27W2jYnx1Fbry5dusSFF14YF154YVOXssXaksbxVVddFQ888MCnvslPU5g3b15UVlbmbsSypTM21s/Y2PxcQxG2IEuWLIm//e1vMXbsWAfBbFfefffduO+++6K6unq7+YoabCjjBRrmOAo2j1XXSv7FL34RV199dVOXk8mf/vSnWLp0aXTv3j3mz58fl1xySXTp0iV3rT3YGLbGsfFpCBRhC3LiiSfG5MmT47vf/W4ce+yxTV0ObDbt2rWLtm3bxi9/+cvcTQ2Ahhkv0DDHUbB5DBo0KO69997o37//VnMd3xUrVsRPfvKTePvtt6N169Zx6KGHxj333POpbhAFq9sax8an4SvPAAAAAEBm7vIMAAAAAGQmUAQAAAAAMhMoAgAAAACZCRQBAAAAgMwEigAAAABAZgJFAAAAACAzgSIAAAAAkJlAEQAAAADITKAIAAAAAGT2/wElLPI0pRli4QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Train Accuracy\": {\n",
      "    \"value\": \"66.1% +- 9.3\"\n",
      "  },\n",
      "  \"Test Accuracy\": {\n",
      "    \"value\": \"55.3% +- 26.0\"\n",
      "  },\n",
      "  \"Statistical parity\": {\n",
      "    \"value\": \"45.5% +- 46.0\"\n",
      "  },\n",
      "  \"Equal opportunity\": {\n",
      "    \"value\": \"40.0% +- 49.0\"\n",
      "  },\n",
      "  \"Positive predictive parity\": {\n",
      "    \"value\": \"34.5% +- 36.5\"\n",
      "  },\n",
      "  \"Negative predictive parity\": {\n",
      "    \"value\": \"31.8% +- 27.9\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "exp3_data = {'Train Accuracy': [0.6666666865348816, 0.6618603467941284, 0.7251908183097839, 0.6590330600738525, 0.7777777910232544, 0.7348034977912903, 0.545660138130188, 0.6511167883872986, 0.45207804441452026, 0.73508620262146], 'Test Accuracy': [0.23622627556324005, 0.7637737393379211, 0.23125115036964417, 0.236164852976799, 0.7637737393379211, 0.7646335959434509, 0.23622627556324005, 0.7643879652023315, 0.7682574987411499, 0.7641422748565674], 'Statistical parity': [1.0, 0.0, 1.0038877725601196, 1.0000921487808228, 0.0, 0.15410158038139343, 1.0, 0.0, 0.39409583806991577, 0.0], 'Equal opportunity': [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], 'Positive predictive parity': [0.3630095475713583, 0.0, 0.3611792096015038, 0.36308761385354743, 0.0, 1.0, 0.3630095475713583, 0.0, 1.0, 0.0], 'Negative predictive parity': [0.0, 0.3630095475713583, 1.0, 0.0, 0.3630095475713583, 0.3634784484000338, 0.0, 0.363792594030022, 0.36117985716154993, 0.3634787750532165]}\n",
    "\n",
    "\n",
    "plot_data(exp3_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 5\n",
    "The Swiglu models were the most stable (low std) and achieved the highest predition accurancies. However, they achieved equal opportunity coefficient of $0$.  \n",
    "The highest equal opportunity was obtained with the model trained on the balanced data. However, training on the balanced data reduced the number of samples and introduced changes between train and test distributions (see point 2).  \n",
    "We hypothesize that this resulted in models expressing the highest std in the evaluation metrics and achieving the lowest accuracy scores.  \n",
    "We note that in the case of a simple model, there is a tradeoff between achieving positive equal opportunity coeff and obtaining a good predictive model.  \n",
    "We also note that acquiring a balanced sample of the training data can increase costs and is a more general problem, such as creation of fair image and text generation models.\n",
    "\n",
    "\n",
    "\n",
    "| Metric                      | Model 1           | Model 2           | Model 3           |\n",
    "|-----------------------------|-------------------|-------------------|-------------------|\n",
    "| **Train Accuracy %**           | 76.7 ± 0.3        | 83.5 ± 0.0        | 66.1 ± 9.3        |\n",
    "| **Test Accuracy %**            | 76.7 ± 0.2        | 77.8 ± 0.5        | 55.3 ± 26.0       |\n",
    "| **Statistical Parity %**       | 30.0 ± 12.5       | 46.5 ± 4.5        | 45.5 ± 46.0       |\n",
    "| **Equal Opportunity %**        | 0.0 ± 0.0         | 0.0 ± 0.0         | 40.0 ± 49.0       |\n",
    "| **Positive Predictive Parity %**| 90.0 ± 30.0       | 89.7 ± 5.4        | 34.5 ± 36.5       |\n",
    "| **Negative Predictive Parity %**| 36.2 ± 0.1        | 35.5 ± 0.4        | 31.8 ± 27.9       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point 6\n",
    "Results are commented in each point separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load and preapare the data about people and their salaries\n",
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "from typing import List, Dict, Callable, Tuple\n",
    "import copy\n",
    "\n",
    "\n",
    "def load_and_prepare_data(data_path: str, description_path: str, norm_spec={}):\n",
    "\n",
    "    def load_data_file(path: str):\n",
    "        with open(path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        result = [\n",
    "            l for l in lines if len(l.strip()) == 0 or l.strip()[0] != \"|\"\n",
    "        ]  # skip comments\n",
    "        return result\n",
    "\n",
    "    def load_data(data_path, description_path):\n",
    "\n",
    "        def clean(x):\n",
    "            if len(x) > 0 and x[-1] == \".\":\n",
    "                return x[:-1]\n",
    "            else:\n",
    "                return x \n",
    "\n",
    "        raw_description = load_data_file(description_path)\n",
    "\n",
    "        description = []\n",
    "        possible_values = []\n",
    "        start = False\n",
    "        for i, rd in enumerate(raw_description):\n",
    "            if rd.startswith(\"age:\"):\n",
    "                start = True\n",
    "\n",
    "            if start:\n",
    "                description.append(rd.split(\":\")[0])\n",
    "                possible_values.append(clean(v) for v in rd.split(\":\")[1].strip()[:-1].split(\",\"))\n",
    "                possible_values[-1] = [pv.strip() for pv in possible_values[-1]]\n",
    "\n",
    "        description.append(\"salary\")\n",
    "        possible_values.append([\">50K\", \"<=50K\"])\n",
    "\n",
    "        raw_data = load_data_file(data_path)\n",
    "\n",
    "        raw_data = [clean(rd.strip()) for rd in raw_data]\n",
    "\n",
    "        raw_data = [\",\".join(description)] + raw_data\n",
    "\n",
    "        raw_data = \"\\n\".join(raw_data)\n",
    "        raw_data = \",\".join(raw_data.split(\", \"))\n",
    "\n",
    "        data_frame = pd.read_csv(StringIO(raw_data))\n",
    "\n",
    "        return data_frame, possible_values\n",
    "\n",
    "    def prepare_data(\n",
    "        data_frame: pd.DataFrame,\n",
    "        possible_values: List[str],\n",
    "        norm_spec: Dict[str, Callable],\n",
    "    ):\n",
    "        norm_spec = copy.deepcopy(norm_spec)\n",
    "        columns = data_frame.columns\n",
    "        assert len(columns) == len(possible_values)\n",
    "        json_data = {}\n",
    "\n",
    "        for c, pv in zip(columns, possible_values):\n",
    "            if len(pv) == 1 and pv[0] == \"continuous\":\n",
    "                if c not in norm_spec:\n",
    "                    minv = data_frame[c].min().item()\n",
    "                    maxv = data_frame[c].max().item()\n",
    "                    interval = max(maxv - minv, 1.0)\n",
    "                    ns = lambda x: (x - minv) / interval\n",
    "                    norm_spec[c] = ns\n",
    "                json_data[c] = norm_spec[c](data_frame[c].to_numpy())\n",
    "            else:\n",
    "                assert len(pv) > 1, pv\n",
    "                for p in pv:\n",
    "                    new_c = c + \"_\" + p\n",
    "                    json_data[new_c] = (data_frame[c] == p).to_numpy()\n",
    "\n",
    "        new_df = pd.DataFrame(json_data)\n",
    "\n",
    "        return new_df, norm_spec\n",
    "\n",
    "    df, pv = load_data(data_path=data_path, description_path=description_path)\n",
    "\n",
    "    df, norm_spec = prepare_data(data_frame=df, possible_values=pv, norm_spec=norm_spec)\n",
    "\n",
    "    return df, norm_spec\n",
    "\n",
    "\n",
    "train_data_path = os.path.join(os.getcwd(), \"adult.data\")\n",
    "test_data_path = os.path.join(os.getcwd(), \"adult.test\")\n",
    "description_path = os.path.join(os.getcwd(), \"adult.names\")\n",
    "\n",
    "train_df, ns = load_and_prepare_data(train_data_path, description_path)\n",
    "test_df, ns = load_and_prepare_data(test_data_path, description_path, norm_spec=ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "TARGET = \"salary_>50K\"\n",
    "REMOVE = [\"salary_<=50K\", \"sex_Female\", \"sex_Male\"]\n",
    "PROTECTED_ATTRIBUTE = [\"sex_Female\", \"sex_Male\"]\n",
    "\n",
    "\n",
    "def data_to_numpy(data: pd.DataFrame, target: str, remove: List[str]):\n",
    "    columns_to_keep = [c for c in data.columns if c not in remove]\n",
    "    json_data = {k: data[k] for k in columns_to_keep}\n",
    "    data = pd.DataFrame(json_data)\n",
    "\n",
    "    y = torch.from_numpy(data[target].to_numpy().astype(np.float32))\n",
    "    columns_without_target = [c for c in columns_to_keep if c != target]\n",
    "    x = torch.from_numpy(data[columns_without_target].to_numpy().astype(np.float32))\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    num_epochs: int,\n",
    "    batch_size: int,\n",
    "    device=DEVICE,\n",
    "    target: str = TARGET,\n",
    "    remove_columns: List[str] = REMOVE,\n",
    "):\n",
    "\n",
    "    test_x, test_y = data_to_numpy(data=test_df, target=target, remove=remove_columns)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def eval_model(x, y):\n",
    "        model.eval()\n",
    "        logits = model(x)\n",
    "        predictions = (logits[..., 1] > logits[..., 0]).to(torch.float32).flatten()\n",
    "\n",
    "        accuracy = (predictions == y.flatten()).to(torch.float32).mean()\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    train_x, train_y = data_to_numpy(\n",
    "        data=train_df, target=target, remove=remove_columns\n",
    "    )\n",
    "    num_samples = train_x.shape[0]\n",
    "\n",
    "    initial_acc = eval_model(test_x, test_y)\n",
    "\n",
    "    print(f\"Initial model accuracy is {initial_acc}\")\n",
    "\n",
    "    epoch_tqdm = tqdm(range(num_epochs))\n",
    "\n",
    "    for e in epoch_tqdm:\n",
    "        model.train()\n",
    "        sample_indices = torch.randperm(num_samples, dtype=torch.long)\n",
    "\n",
    "        for b_start in tqdm(range(0, num_samples, batch_size), desc=\"batch\"):\n",
    "            optimizer.zero_grad()\n",
    "            b_end = min(b_start + batch_size, num_samples)\n",
    "            b_ids = sample_indices[b_start:b_end]\n",
    "\n",
    "            batch_x = train_x[b_ids].to(device)\n",
    "            batch_y = train_y[b_ids].to(device).flatten()\n",
    "            logits = model(batch_x)\n",
    "\n",
    "            log_prob = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "            loss = batch_y * log_prob[:, 1] + (1 - batch_y) * log_prob[:, 0]\n",
    "            loss = -loss.mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        acc = eval_model(test_x, test_y)\n",
    "        acc_train = eval_model(train_x.to(device), train_y.to(device))\n",
    "        epoch_tqdm.set_description(\n",
    "            f\"Loss {loss.detach()} At the end of epoch {e} test accuracy is {acc} and train {acc_train}\"\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        eval_model(test_x, test_y).numpy().item(),\n",
    "        eval_model(train_x.to(device), train_y.to(device)).numpy().item(),\n",
    "    )\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def analyze_fairness(\n",
    "    model: torch.nn.Module,\n",
    "    test_df: pd.DataFrame,\n",
    "    protected_ids: str = PROTECTED_ATTRIBUTE,\n",
    "    target: str = TARGET,\n",
    "    remove_columns: List[str] = REMOVE,\n",
    "    device=DEVICE,\n",
    "):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    test_x, test_y = data_to_numpy(data=test_df, target=target, remove=remove_columns)\n",
    "    test_x = test_x.to(device)\n",
    "    test_y = test_y.to(device)\n",
    "\n",
    "    logits = model(test_x)\n",
    "    assert len(logits.shape) == 2\n",
    "    predictions = (logits[:, 1] > logits[:, 0]).cpu().numpy().astype(np.float32)\n",
    "\n",
    "    def calc_statistical_parity(df, predictions):\n",
    "\n",
    "        gr_a = df[protected_ids[0]].to_numpy()\n",
    "        gr_b = df[protected_ids[1]].to_numpy()\n",
    "\n",
    "        pos_a = predictions[gr_a].mean()\n",
    "        pos_b = predictions[gr_b].mean()\n",
    "\n",
    "        return np.nan_to_num(pos_a / max(pos_b, 1e-7)).item()\n",
    "\n",
    "    def calc_eq_opportunity(df, predictions, gt):\n",
    "\n",
    "        gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
    "        gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n",
    "\n",
    "        pos_a = predictions[gr_a_t].mean()\n",
    "        pos_b = predictions[gr_b_t].mean()\n",
    "\n",
    "        return np.nan_to_num(pos_a / max(pos_b, 1e-7)).item()\n",
    "\n",
    "    def calc_pred_parity(df, predictions, gt):\n",
    "        gr_a_p = np.logical_and(df[protected_ids[0]].to_numpy(), predictions)\n",
    "        gr_b_p = np.logical_and(df[protected_ids[1]].to_numpy(), predictions)\n",
    "\n",
    "        pos_pred_rate_parity = np.nan_to_num(\n",
    "            np.nan_to_num(gt[gr_a_p].mean().item())\n",
    "            / max(np.nan_to_num(gt[gr_b_p].mean()).item(), 1e-7)\n",
    "        )\n",
    "\n",
    "        gr_a_np = np.logical_and(\n",
    "            df[protected_ids[0]].to_numpy(), np.logical_not(predictions)\n",
    "        )\n",
    "        gr_b_np = np.logical_and(\n",
    "            df[protected_ids[1]].to_numpy(), np.logical_not(predictions)\n",
    "        )\n",
    "\n",
    "        neg_pred_rate_parity = np.nan_to_num(\n",
    "            np.nan_to_num(gt[gr_a_np].mean().item())\n",
    "            / max(np.nan_to_num(gt[gr_b_np].mean()).item(), 1e-7)\n",
    "        )\n",
    "\n",
    "        return pos_pred_rate_parity.item(), neg_pred_rate_parity.item()\n",
    "\n",
    "    stat_parity = calc_statistical_parity(df=test_df, predictions=predictions)\n",
    "\n",
    "    eq_opport = calc_eq_opportunity(df=test_df, predictions=predictions, gt=test_y)\n",
    "\n",
    "    pos_pred_par, neg_pred_par = calc_pred_parity(\n",
    "        df=test_df, predictions=predictions, gt=test_y\n",
    "    )\n",
    "\n",
    "    res = {\n",
    "        \"Statistical parity\": stat_parity,\n",
    "        \"Equal opportunity\": eq_opport,\n",
    "        \"Positive predictive parity\": pos_pred_par,\n",
    "        \"Negative predictive parity\": neg_pred_par,\n",
    "    }\n",
    "\n",
    "    print(json.dumps(res, indent=2))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwigluBlock(torch.nn.Module):\n",
    "    def __init__(self, in_dim: int, inner_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up_proj = torch.nn.Linear(\n",
    "            in_features=in_dim, out_features=inner_dim, bias=True\n",
    "        )\n",
    "        self.gate = torch.nn.Linear(\n",
    "            in_features=in_dim, out_features=inner_dim, bias=True\n",
    "        )\n",
    "        self.down_proj = torch.nn.Linear(\n",
    "            in_features=inner_dim, out_features=out_dim, bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        u = self.up_proj(x)\n",
    "        g = self.gate(x)\n",
    "\n",
    "        y = u * torch.nn.functional.silu(g)\n",
    "        z = self.down_proj(y)\n",
    "\n",
    "        return z\n",
    "    \n",
    "\n",
    "class SimpleLinear(torch.nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj = torch.nn.Linear(\n",
    "            in_features=in_dim, out_features=out_dim, bias=True\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "\n",
    "        return self.proj(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "Initial model accuracy is 0.23622627556324005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1713.67it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1609.65it/s]y is 0.23622627556324005 and train 0.759374737739563:  33%|███▎      | 1/3 [00:00<00:00,  3.32it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1620.40it/s]y is 0.7747681140899658 and train 0.7602346539497375:  67%|██████▋   | 2/3 [00:00<00:00,  3.19it/s]\n",
      "Loss 0.393289715051651 At the end of epoch 2 test accuracy is 0.7715128064155579 and train 0.7660084366798401: 100%|██████████| 3/3 [00:00<00:00,  3.19it/s] \n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.3557297885417938,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.36094293261038035\n",
      "}\n",
      "Model 1\n",
      "Initial model accuracy is 0.7637737393379211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 2281.92it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1153.41it/s] is 0.7638965845108032 and train 0.759466826915741:  33%|███▎      | 1/3 [00:00<00:00,  4.35it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1125.87it/s]cy is 0.7643265128135681 and train 0.7610945701599121:  67%|██████▋   | 2/3 [00:00<00:00,  2.80it/s]\n",
      "Loss 0.4660312533378601 At the end of epoch 2 test accuracy is 0.7643879652023315 and train 0.7725499868392944: 100%|██████████| 3/3 [00:01<00:00,  2.64it/s] \n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.0,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.0,\n",
      "  \"Negative predictive parity\": 0.363792594030022\n",
      "}\n",
      "Model 2\n",
      "Initial model accuracy is 0.23622627556324005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1166.28it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1099.83it/s]y is 0.765677809715271 and train 0.7591904401779175:  33%|███▎      | 1/3 [00:00<00:00,  2.27it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1103.02it/s]cy is 0.7660462856292725 and train 0.7594975829124451:  67%|██████▋   | 2/3 [00:00<00:00,  2.18it/s]\n",
      "Loss 0.4865451753139496 At the end of epoch 2 test accuracy is 0.7662919759750366 and train 0.7654862999916077: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s] \n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.41244831681251526,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.36182020302885015\n",
      "}\n",
      "Model 3\n",
      "Initial model accuracy is 0.3720901608467102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 2635.62it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1492.72it/s]y is 0.7668448090553284 and train 0.7592211365699768:  33%|███▎      | 1/3 [00:00<00:00,  5.03it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1147.54it/s]y is 0.7667833566665649 and train 0.7596818208694458:  67%|██████▋   | 2/3 [00:00<00:00,  3.49it/s]\n",
      "Loss 0.4607338309288025 At the end of epoch 2 test accuracy is 0.766906201839447 and train 0.7631215453147888: 100%|██████████| 3/3 [00:00<00:00,  3.01it/s] \n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.3727107644081116,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.361977067761774\n",
      "}\n",
      "Model 4\n",
      "Initial model accuracy is 0.23622627556324005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1129.98it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1136.96it/s]y is 0.7761194109916687 and train 0.7599582076072693:  33%|███▎      | 1/3 [00:00<00:00,  2.20it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1097.56it/s]y is 0.7707143425941467 and train 0.7606953382492065:  67%|██████▋   | 2/3 [00:00<00:00,  2.20it/s]\n",
      "Loss 0.47550061345100403 At the end of epoch 2 test accuracy is 0.7697315812110901 and train 0.7657627463340759: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.31003767251968384,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.362462880973088\n",
      "}\n",
      "Model 5\n",
      "Initial model accuracy is 0.7685645818710327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1138.30it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1166.17it/s]y is 0.7659848928451538 and train 0.7610331177711487:  33%|███▎      | 1/3 [00:00<00:00,  2.21it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1106.22it/s]cy is 0.7661077380180359 and train 0.7623844742774963:  67%|██████▋   | 2/3 [00:00<00:00,  2.24it/s]\n",
      "Loss 0.47792357206344604 At the end of epoch 2 test accuracy is 0.7664762735366821 and train 0.7690488696098328: 100%|██████████| 3/3 [00:01<00:00,  2.21it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.379006564617157,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.3620570216011652\n",
      "}\n",
      "Model 6\n",
      "Initial model accuracy is 0.765677809715271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 2382.41it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 2161.94it/s]y is 0.7652478218078613 and train 0.7594361305236816:  33%|███▎      | 1/3 [00:00<00:00,  4.59it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1150.94it/s]y is 0.7655549645423889 and train 0.7611867189407349:  67%|██████▋   | 2/3 [00:00<00:00,  4.33it/s]\n",
      "Loss 0.48946714401245117 At the end of epoch 2 test accuracy is 0.7660462856292725 and train 0.7693559527397156: 100%|██████████| 3/3 [00:00<00:00,  3.31it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.3877394497394562,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.36213712085178934\n",
      "}\n",
      "Model 7\n",
      "Initial model accuracy is 0.23063693940639496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1241.49it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1187.01it/s]y is 0.7641422748565674 and train 0.7631215453147888:  33%|███▎      | 1/3 [00:00<00:00,  2.42it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1123.63it/s]y is 0.7645722031593323 and train 0.7638586163520813:  67%|██████▋   | 2/3 [00:00<00:00,  2.35it/s]\n",
      "Loss 0.46921446919441223 At the end of epoch 2 test accuracy is 0.7652478218078613 and train 0.7695402503013611: 100%|██████████| 3/3 [00:01<00:00,  2.29it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.18212004005908966,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.36363637044606123\n",
      "}\n",
      "Model 8\n",
      "Initial model accuracy is 0.23475216329097748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1160.64it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1858.60it/s]y is 0.7643879652023315 and train 0.7559964656829834:  33%|███▎      | 1/3 [00:00<00:00,  2.25it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1349.58it/s]y is 0.7650021314620972 and train 0.7594054341316223:  67%|██████▋   | 2/3 [00:00<00:00,  2.88it/s]\n",
      "Loss 0.4808824956417084 At the end of epoch 2 test accuracy is 0.7657392024993896 and train 0.7616166472434998: 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.2072400450706482,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.3636375185000986\n",
      "}\n",
      "Model 9\n",
      "Initial model accuracy is 0.23475216329097748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1104.79it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1108.30it/s]y is 0.23180393874645233 and train 0.7590062022209167:  33%|███▎      | 1/3 [00:00<00:00,  2.15it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1139.10it/s]cy is 0.7657392024993896 and train 0.760388195514679:  67%|██████▋   | 2/3 [00:00<00:00,  2.15it/s] \n",
      "Loss 0.3731554448604584 At the end of epoch 2 test accuracy is 0.7667833566665649 and train 0.7670833468437195: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.39089176058769226,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.3618187522840974\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    }
   ],
   "source": [
    "exp1_fairness_data = {\"Train Accuracy\": [], \"Test Accuracy\": []}\n",
    "torch.manual_seed(42)\n",
    "for i in range(10):\n",
    "    print(f\"Model {i}\")\n",
    "    model = SimpleLinear(in_dim=103, out_dim=2)\n",
    "    model.to(DEVICE)\n",
    "    optim = torch.optim.AdamW(params=model.parameters(), lr=1e-4, weight_decay=0.1)\n",
    "\n",
    "    final_acc_test, final_acc_train = train(\n",
    "        model=model,\n",
    "        optimizer=optim,\n",
    "        train_df=train_df,\n",
    "        test_df=test_df,\n",
    "        num_epochs=3,\n",
    "        batch_size=64,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    res = analyze_fairness(model=model, test_df=test_df)\n",
    "    for k, v in res.items():\n",
    "        if k not in exp1_fairness_data:\n",
    "            exp1_fairness_data[k] = []\n",
    "        exp1_fairness_data[k].append(v)\n",
    "    exp1_fairness_data[\"Test Accuracy\"].append(final_acc_test)\n",
    "    exp1_fairness_data[\"Train Accuracy\"].append(final_acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "Initial model accuracy is 0.7637737393379211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 548.46it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 583.65it/s]acy is 0.7691173553466797 and train 0.819661557674408:  33%|███▎      | 1/3 [00:00<00:01,  1.01it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1127.96it/s]y is 0.7731097340583801 and train 0.8323761820793152:  67%|██████▋   | 2/3 [00:01<00:00,  1.05it/s]\n",
      "Loss 0.29701974987983704 At the end of epoch 2 test accuracy is 0.7787604928016663 and train 0.8355701565742493: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.48467427492141724,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.8701754351842217,\n",
      "  \"Negative predictive parity\": 0.3543193296076082\n",
      "}\n",
      "Model 1\n",
      "Initial model accuracy is 0.77501380443573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 1155.29it/s]\n",
      "batch: 100%|██████████| 509/509 [00:01<00:00, 501.06it/s]cy is 0.7693630456924438 and train 0.8215656876564026:  33%|███▎      | 1/3 [00:00<00:01,  1.97it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 716.04it/s]acy is 0.773908257484436 and train 0.8326525688171387:  67%|██████▋   | 2/3 [00:01<00:00,  1.19it/s]\n",
      "Loss 0.5406938195228577 At the end of epoch 2 test accuracy is 0.7807260155677795 and train 0.8348944783210754: 100%|██████████| 3/3 [00:02<00:00,  1.28it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.5061770677566528,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.859045759047395,\n",
      "  \"Negative predictive parity\": 0.35220900206066963\n",
      "}\n",
      "Model 2\n",
      "Initial model accuracy is 0.7694244980812073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 568.07it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 545.10it/s]cy is 0.766906201839447 and train 0.8194465637207031:  33%|███▎      | 1/3 [00:00<00:01,  1.03it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 877.72it/s]cy is 0.7704071998596191 and train 0.8321611881256104:  67%|██████▋   | 2/3 [00:01<00:00,  1.01it/s]\n",
      "Loss 0.299884170293808 At the end of epoch 2 test accuracy is 0.7730483412742615 and train 0.8353244662284851: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s] \n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.40977007150650024,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.9853574512091914,\n",
      "  \"Negative predictive parity\": 0.358722841495906\n",
      "}\n",
      "Model 3\n",
      "Initial model accuracy is 0.7637737393379211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 717.57it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 554.43it/s]acy is 0.7680118083953857 and train 0.8252817988395691:  33%|███▎      | 1/3 [00:00<00:01,  1.29it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 941.69it/s] cy is 0.7712671160697937 and train 0.8326525688171387:  67%|██████▋   | 2/3 [00:01<00:00,  1.11it/s]\n",
      "Loss 0.3740980923175812 At the end of epoch 2 test accuracy is 0.773908257484436 and train 0.8352937698364258: 100%|██████████| 3/3 [00:02<00:00,  1.27it/s]  \n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.42454472184181213,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.9049657560108297,\n",
      "  \"Negative predictive parity\": 0.3591010453033186\n",
      "}\n",
      "Model 4\n",
      "Initial model accuracy is 0.7637737393379211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 940.81it/s]\n",
      "batch: 100%|██████████| 509/509 [00:01<00:00, 491.64it/s]acy is 0.7653706669807434 and train 0.8241147398948669:  33%|███▎      | 1/3 [00:00<00:01,  1.64it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 568.83it/s]cy is 0.769608736038208 and train 0.8321918845176697:  67%|██████▋   | 2/3 [00:01<00:00,  1.11it/s]  \n",
      "Loss 0.4343719780445099 At the end of epoch 2 test accuracy is 0.772986888885498 and train 0.8350480794906616: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.41289809346199036,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.9855324267881331,\n",
      "  \"Negative predictive parity\": 0.3586415825127496\n",
      "}\n",
      "Model 5\n",
      "Initial model accuracy is 0.23469074070453644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 693.19it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 567.93it/s]cy is 0.7657392024993896 and train 0.8171738982200623:  33%|███▎      | 1/3 [00:00<00:01,  1.24it/s]\n",
      "batch: 100%|██████████| 509/509 [00:01<00:00, 492.92it/s]acy is 0.7716970443725586 and train 0.8320997357368469:  67%|██████▋   | 2/3 [00:01<00:00,  1.12it/s]\n",
      "Loss 0.5590869188308716 At the end of epoch 2 test accuracy is 0.7769793272018433 and train 0.8352630734443665: 100%|██████████| 3/3 [00:02<00:00,  1.05it/s] \n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.48005837202072144,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.9017201066090681,\n",
      "  \"Negative predictive parity\": 0.3547010881548059\n",
      "}\n",
      "Model 6\n",
      "Initial model accuracy is 0.23505927622318268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 638.87it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 527.24it/s]cy is 0.7667219638824463 and train 0.8244218826293945:  33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]\n",
      "batch: 100%|██████████| 509/509 [00:01<00:00, 436.94it/s]cy is 0.7724955677986145 and train 0.8326525688171387:  67%|██████▋   | 2/3 [00:01<00:00,  1.03it/s]\n",
      "Loss 0.37257257103919983 At the end of epoch 2 test accuracy is 0.7785148620605469 and train 0.8348023891448975: 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.4560404419898987,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.8746838994979308,\n",
      "  \"Negative predictive parity\": 0.35584695909770386\n",
      "}\n",
      "Model 7\n",
      "Initial model accuracy is 0.23505927622318268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 601.92it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 674.88it/s]acy is 0.7693630456924438 and train 0.8193544149398804:  33%|███▎      | 1/3 [00:00<00:01,  1.08it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 544.13it/s]cy is 0.7745838761329651 and train 0.8319768905639648:  67%|██████▋   | 2/3 [00:01<00:00,  1.15it/s] \n",
      "Loss 0.4276393949985504 At the end of epoch 2 test accuracy is 0.7860696315765381 and train 0.8349559307098389: 100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.53014075756073,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.8242809320028235,\n",
      "  \"Negative predictive parity\": 0.3478771255876427\n",
      "}\n",
      "Model 8\n",
      "Initial model accuracy is 0.23622627556324005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 637.75it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 549.73it/s]cy is 0.7695473432540894 and train 0.8235926628112793:  33%|███▎      | 1/3 [00:00<00:01,  1.14it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 562.15it/s]acy is 0.7762422561645508 and train 0.8324990272521973:  67%|██████▋   | 2/3 [00:01<00:00,  1.05it/s]\n",
      "Loss 0.28995180130004883 At the end of epoch 2 test accuracy is 0.7866838574409485 and train 0.8351094722747803: 100%|██████████| 3/3 [00:02<00:00,  1.05it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.5269279479980469,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.8296935048568537,\n",
      "  \"Negative predictive parity\": 0.34739712500282677\n",
      "}\n",
      "Model 9\n",
      "Initial model accuracy is 0.23395368456840515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 509/509 [00:00<00:00, 655.84it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 572.09it/s]cy is 0.7670904994010925 and train 0.8224869966506958:  33%|███▎      | 1/3 [00:00<00:01,  1.17it/s]\n",
      "batch: 100%|██████████| 509/509 [00:00<00:00, 719.85it/s]cy is 0.7707143425941467 and train 0.8320997357368469:  67%|██████▋   | 2/3 [00:01<00:00,  1.09it/s]\n",
      "Loss 0.2635990381240845 At the end of epoch 2 test accuracy is 0.773908257484436 and train 0.835201621055603: 100%|██████████| 3/3 [00:02<00:00,  1.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.41401955485343933,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.9343715229552395,\n",
      "  \"Negative predictive parity\": 0.3589525200363936\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    }
   ],
   "source": [
    "exp2_fairness_data = {\"Train Accuracy\": [], \"Test Accuracy\": []}\n",
    "torch.manual_seed(42)\n",
    "for i in range(10):\n",
    "    print(f\"Model {i}\")\n",
    "    model = SwigluBlock(in_dim=103, inner_dim=256, out_dim=2)\n",
    "    model.to(DEVICE)\n",
    "    optim = torch.optim.AdamW(params=model.parameters(), lr=1e-4, weight_decay=0.1)\n",
    "\n",
    "    final_acc_test, final_acc_train = train(\n",
    "        model=model,\n",
    "        optimizer=optim,\n",
    "        train_df=train_df,\n",
    "        test_df=test_df,\n",
    "        num_epochs=3,\n",
    "        batch_size=64,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    res = analyze_fairness(model=model, test_df=test_df)\n",
    "    for k, v in res.items():\n",
    "        if k not in exp2_fairness_data:\n",
    "            exp2_fairness_data[k] = []\n",
    "        exp2_fairness_data[k].append(v)\n",
    "    exp2_fairness_data[\"Test Accuracy\"].append(final_acc_test)\n",
    "    exp2_fairness_data[\"Train Accuracy\"].append(final_acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "Initial model accuracy is 0.23622627556324005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1791.23it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1202.77it/s]acy is 0.23622627556324005 and train 0.6454622745513916:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2289.40it/s]acy is 0.23622627556324005 and train 0.6621430516242981:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Loss 0.6261046528816223 At the end of epoch 2 test accuracy is 0.23622627556324005 and train 0.6666666865348816: 100%|██████████| 3/3 [00:00<00:00, 25.28it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 1.0,\n",
      "  \"Equal opportunity\": 1.0,\n",
      "  \"Positive predictive parity\": 0.3630095475713583,\n",
      "  \"Negative predictive parity\": 0.0\n",
      "}\n",
      "Model 1\n",
      "Initial model accuracy is 0.7637737393379211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1063.35it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2423.78it/s]acy is 0.7637737393379211 and train 0.4195646047592163:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2241.77it/s]acy is 0.7637737393379211 and train 0.5253039002418518:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Loss 0.6877762079238892 At the end of epoch 2 test accuracy is 0.7637737393379211 and train 0.6618603467941284: 100%|██████████| 3/3 [00:00<00:00, 26.54it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.0,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.0,\n",
      "  \"Negative predictive parity\": 0.3630095475713583\n",
      "}\n",
      "Model 2\n",
      "Initial model accuracy is 0.23303237557411194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2543.71it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1637.45it/s]cy is 0.23260241746902466 and train 0.7037037014961243:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2193.14it/s]acy is 0.23198820650577545 and train 0.7178399562835693:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Loss 0.594783365726471 At the end of epoch 2 test accuracy is 0.23125115036964417 and train 0.7251908183097839: 100%|██████████| 3/3 [00:00<00:00, 32.27it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 1.0038877725601196,\n",
      "  \"Equal opportunity\": 1.0,\n",
      "  \"Positive predictive parity\": 0.3611792096015038,\n",
      "  \"Negative predictive parity\": 1.0\n",
      "}\n",
      "Model 3\n",
      "Initial model accuracy is 0.235857754945755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2334.15it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1360.43it/s]acy is 0.235857754945755 and train 0.601357102394104:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2823.22it/s]acy is 0.23604200780391693 and train 0.6375459432601929:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Loss 0.6297588348388672 At the end of epoch 2 test accuracy is 0.236164852976799 and train 0.6590330600738525: 100%|██████████| 3/3 [00:00<00:00, 31.78it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 1.0000921487808228,\n",
      "  \"Equal opportunity\": 1.0,\n",
      "  \"Positive predictive parity\": 0.36308761385354743,\n",
      "  \"Negative predictive parity\": 0.0\n",
      "}\n",
      "Model 4\n",
      "Initial model accuracy is 0.22209937870502472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1089.02it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1101.58it/s]acy is 0.20459431409835815 and train 0.6844783425331116:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1112.87it/s]acy is 0.7637122869491577 and train 0.7480915784835815:  67%|██████▋   | 2/3 [00:00<00:00, 18.09it/s]\n",
      "Loss 0.6101513504981995 At the end of epoch 2 test accuracy is 0.7637737393379211 and train 0.7777777910232544: 100%|██████████| 3/3 [00:00<00:00, 18.12it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.0,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.0,\n",
      "  \"Negative predictive parity\": 0.3630095475713583\n",
      "}\n",
      "Model 5\n",
      "Initial model accuracy is 0.7646335959434509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1422.48it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2729.94it/s]acy is 0.7645722031593323 and train 0.6415041089057922:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1791.43it/s]acy is 0.7645722031593323 and train 0.6963528394699097:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Loss 0.639954149723053 At the end of epoch 2 test accuracy is 0.7646335959434509 and train 0.7348034977912903: 100%|██████████| 3/3 [00:00<00:00, 30.39it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.15410158038139343,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.3634784484000338\n",
      "}\n",
      "Model 6\n",
      "Initial model accuracy is 0.23622627556324005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1097.72it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2532.79it/s]acy is 0.23622627556324005 and train 0.4076901376247406:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1269.95it/s]acy is 0.23622627556324005 and train 0.47045519948005676:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Loss 0.6983863711357117 At the end of epoch 2 test accuracy is 0.23622627556324005 and train 0.545660138130188: 100%|██████████| 3/3 [00:00<00:00, 22.97it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 1.0,\n",
      "  \"Equal opportunity\": 1.0,\n",
      "  \"Positive predictive parity\": 0.3630095475713583,\n",
      "  \"Negative predictive parity\": 0.0\n",
      "}\n",
      "Model 7\n",
      "Initial model accuracy is 0.7641422748565674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1242.09it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1146.96it/s]acy is 0.7642651200294495 and train 0.452643483877182:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2524.27it/s]acy is 0.7643265128135681 and train 0.5493355989456177:  67%|██████▋   | 2/3 [00:00<00:00, 19.19it/s]\n",
      "Loss 0.6983003616333008 At the end of epoch 2 test accuracy is 0.7643879652023315 and train 0.6511167883872986: 100%|██████████| 3/3 [00:00<00:00, 22.88it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.0,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.0,\n",
      "  \"Negative predictive parity\": 0.363792594030022\n",
      "}\n",
      "Model 8\n",
      "Initial model accuracy is 0.2365948110818863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1942.55it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2117.06it/s]acy is 0.7724955677986145 and train 0.3452078104019165:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1213.81it/s]acy is 0.7694244980812073 and train 0.3754594326019287:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Loss 0.7009738087654114 At the end of epoch 2 test accuracy is 0.7682574987411499 and train 0.45207804441452026: 100%|██████████| 3/3 [00:00<00:00, 25.46it/s]\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.39409583806991577,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 1.0,\n",
      "  \"Negative predictive parity\": 0.36117985716154993\n",
      "}\n",
      "Model 9\n",
      "Initial model accuracy is 0.7638351321220398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch: 100%|██████████| 56/56 [00:00<00:00, 1827.13it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2315.58it/s]acy is 0.7638965845108032 and train 0.5507492423057556:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "batch: 100%|██████████| 56/56 [00:00<00:00, 2080.07it/s]cy is 0.764080822467804 and train 0.6632739901542664:   0%|          | 0/3 [00:00<?, ?it/s]  \n",
      "Loss 0.661750316619873 At the end of epoch 2 test accuracy is 0.7641422748565674 and train 0.73508620262146: 100%|██████████| 3/3 [00:00<00:00, 31.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Statistical parity\": 0.0,\n",
      "  \"Equal opportunity\": 0.0,\n",
      "  \"Positive predictive parity\": 0.0,\n",
      "  \"Negative predictive parity\": 0.3634787750532165\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_640952/4146891610.py:125: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_a_t = np.logical_and(df[protected_ids[0]].to_numpy(), gt)\n",
      "/tmp/ipykernel_640952/4146891610.py:126: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gr_b_t = np.logical_and(df[protected_ids[1]].to_numpy(), gt)\n"
     ]
    }
   ],
   "source": [
    "exp3_fairness_data = {\"Train Accuracy\": [], \"Test Accuracy\": []}\n",
    "torch.manual_seed(42)\n",
    "for i in range(10):\n",
    "    print(f\"Model {i}\")\n",
    "    model = SimpleLinear(in_dim=103, out_dim=2)\n",
    "    model.to(DEVICE)\n",
    "    optim = torch.optim.AdamW(params=model.parameters(), lr=1e-4, weight_decay=0.1)\n",
    "\n",
    "    gr_a_data = train_df[train_df[PROTECTED_ATTRIBUTE[0]]]\n",
    "    gr_b_data = train_df[train_df[PROTECTED_ATTRIBUTE[1]]]\n",
    "\n",
    "    gr_a_neg = gr_a_data[np.logical_not(gr_a_data[TARGET].to_numpy())]\n",
    "    gr_a_pos = gr_a_data[gr_a_data[TARGET]]\n",
    "\n",
    "\n",
    "    gr_b_neg = gr_b_data[np.logical_not(gr_b_data[TARGET].to_numpy())]\n",
    "    gr_b_pos = gr_b_data[gr_b_data[TARGET].to_numpy()]\n",
    "\n",
    "\n",
    "    min_len = min(len(gr_a_neg), len(gr_a_pos), len(gr_b_neg), len(gr_b_pos))\n",
    "\n",
    "    gr_a_neg = gr_a_neg.iloc[:min_len]\n",
    "    gr_a_pos = gr_a_pos.iloc[:min_len]\n",
    "\n",
    "\n",
    "    gr_b_neg = gr_b_neg.iloc[:min_len]\n",
    "    gr_b_pos = gr_b_pos.iloc[:min_len]\n",
    "\n",
    "\n",
    "    ballanced_train_df = pd.concat([gr_a_neg, gr_a_pos, gr_b_neg], axis=0)\n",
    "\n",
    "    final_acc_test, final_acc_train = train(\n",
    "        model=model,\n",
    "        optimizer=optim,\n",
    "        train_df=ballanced_train_df,\n",
    "        test_df=test_df,\n",
    "        num_epochs=3,\n",
    "        batch_size=64,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    res = analyze_fairness(model=model, test_df=test_df)\n",
    "    for k, v in res.items():\n",
    "        if k not in exp3_fairness_data:\n",
    "            exp3_fairness_data[k] = []\n",
    "        exp3_fairness_data[k].append(v)\n",
    "    exp3_fairness_data[\"Test Accuracy\"].append(final_acc_test)\n",
    "    exp3_fairness_data[\"Train Accuracy\"].append(final_acc_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
